{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0164e865",
      "metadata": {
        "id": "0164e865"
      },
      "source": [
        "# AA3 - Práctica 3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a65fbaba",
      "metadata": {
        "id": "a65fbaba"
      },
      "source": [
        "**Andrés Lires Saborido - andres.lires@udc.es**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c501d2a9",
      "metadata": {
        "id": "c501d2a9"
      },
      "source": [
        "### Descripción\n",
        "\n",
        "En este ejercicio se va a crear un sistema de aprendizaje supervisado sobre el dataset CIFAR-100. Consta de las siguientes particiones:\n",
        "\n",
        "- **train**: 50.000 ejemplos etiquetados en 100 clases\n",
        "- **test**: 10.000 ejemplos etiquetados en 100 clases\n",
        "\n",
        "De los datos de train, se deberán de eliminar el 80% de las etiquetas. Para ello usa el siguiente código:\n",
        "\n",
        "```python\n",
        "np.random.seed(125)\n",
        "p = np.random.randn(len(train_label), 1)\n",
        "unlabelled_data = train_dat[p > 0.2]\n",
        "train_data = train_data[p <= 0.2]\n",
        "train_label = train_label[p <= 0.2]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d57d80db",
      "metadata": {
        "id": "d57d80db"
      },
      "source": [
        "### Trabajo a realizar\n",
        "\n",
        "1. Entrena un modelo, creado sobre Tensorflow, haciendo uso únicamente de los datos etiquetados en train. Dicho modelo tiene que ser enteramente convolucional, a excepción de la última capa. El número de capas convolucionales no será inferior a 4. Responde a las siguientes preguntas:\n",
        "\n",
        "    - ¿Qué red has escogido? ¿Cómo la has entrenado?\n",
        "    - ¿Cuál es la precisión del modelo en entrenamiento? ¿Y en test?\n",
        "    - ¿Qué conclusiones sacas de los resultados del punto anterior?\n",
        "\n",
        "\n",
        "2. Entrena el mismo modelo mediante la técnica de auto aprendizaje. Será obligatorio ponderar cada ejemplo de entrada en función de su calidad (o certeza). Responde a las siguientes preguntas:\n",
        "\n",
        "    - ¿Qué parámetros has definido para el entrenamiento?\n",
        "    - ¿Cuál es la precisión del modelo en entrenamiento? ¿Y en test?\n",
        "    - ¿Se mejoran los resultados obtenidos en el ejercicio anterior?\n",
        "    - ¿Qué conclusiones sacas de los resultados del punto anterior?\n",
        "\n",
        "3. Entrena un modelo de aprendizaje semisupervisado de tipo autoencoder en dos pasos (primero el autoencoder, después el clasificador). Se cumplirán los siguientes requisitos:\n",
        "\n",
        "    - La arquitectura del encoder tiene que ser exactamente la misma a la utilizada en el clasificador definido anteriormente en el ejercicio 1, a excepción la última capa y de la capa anterior de Pooling (si existe).\n",
        "    - Se prohíbe el uso de capas Dense en el decoder, esto es, el autoencoder será totalmente convolucional.\n",
        "\n",
        "    Responde a las siguientes preguntas:\n",
        "\n",
        "    1. ¿Cuál es la arquitectura del modelo? ¿Y sus hiperparámetros (epochs, batch size, optimizador, ...)?\n",
        "    2. ¿Cuál es la precisión del modelo en entrenamiento? ¿Y en test?\n",
        "    3. ¿Se mejoran los resultados obtenidos en los puntos anteriores?\n",
        "    4. ¿Qué conclusiones sacas de este apartado?\n",
        "\n",
        "4. Entrena un modelo de aprendizaje semisupervisado de tipo autoencoder en un paso (autoencoder y clasificador al mismo tiempo). Se cumplirán los siguientes puntos:\n",
        "\n",
        "    - La arquitectura del autoencoder será exactamente la misma del punto 3.\n",
        "    - El resultado de combinar el encoder con el clasificador será exactamente igual a la arquitectura definida en el punto 1.\n",
        "\n",
        "    Responde a las siguientes preguntas:\n",
        "\n",
        "    1. ¿Cuál es la arquitectura del modelo? ¿Y sus hiperparámetros (epochs, batch size, optimizador, ...)?\n",
        "    2. ¿Cuál es la precisión del modelo en entrenamiento? ¿Y en test?\n",
        "    3. ¿Se mejoran los resultados obtenidos en los puntos anteriores?\n",
        "    4. ¿Qué conclusiones sacas de este apartado?\n",
        "\n",
        "5. Repite el mismo entrenamiento de los 4 ejercicios anteriores, pero eliminando los datos sin etiquetar más atípicos con respecto a los datos etiquetados. Se cumplirán los siguientes puntos:\n",
        "\n",
        "    - La arquitectura de la red one-class tiene que ser exactamente la misma a la utilizada en el clasificador definido anteriormente en el ejercicio 1, a excepción de la capa de salida.\n",
        "    - Utiliza la técnica explicada en el lab9, usando un valor de ν=0.9.\n",
        "\n",
        "    Responde a la siguiente pregunta: ¿Se mejoran los resultados?\n",
        "\n",
        "6. Repite los puntos 3, 4 y 5, pero cambiando el autoencoder por la técnica definida en el apartado \"Hay vida más allá del autoencoder\" del lab8 de prácticas. Contesta a las preguntas de dichos puntos. Se cumplirán los siguientes puntos:\n",
        "\n",
        "    - La arquitectura de la red será igual a la parte del encoder del autoencoder que hayas definido en los puntos anteriores.\n",
        "    - El modelo tiene que entrenar correctamente."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc8a2ec7",
      "metadata": {
        "id": "fc8a2ec7"
      },
      "source": [
        "### Resolución práctica"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0919f6a6",
      "metadata": {
        "id": "0919f6a6"
      },
      "source": [
        "#### 1. Carga de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b1b8055",
      "metadata": {
        "id": "2b1b8055"
      },
      "source": [
        "Importamos las librerías necesarias:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "765ceee7",
      "metadata": {
        "id": "765ceee7"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5a89270",
      "metadata": {
        "id": "f5a89270"
      },
      "source": [
        "Cargamos el dataset CIFAR-100:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b4b28148",
      "metadata": {
        "id": "b4b28148"
      },
      "outputs": [],
      "source": [
        "(x_train, y_train), (x_test, y_test), = tf.keras.datasets.cifar100.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ea310f8",
      "metadata": {
        "id": "1ea310f8"
      },
      "source": [
        "Comprobamos que el dataset se ha cargado correctamente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "88fc0b4a",
      "metadata": {
        "id": "88fc0b4a"
      },
      "outputs": [],
      "source": [
        "assert x_train.shape == (50000, 32, 32, 3)\n",
        "assert x_test.shape == (10000, 32, 32, 3)\n",
        "assert y_train.shape == (50000, 1)\n",
        "assert y_test.shape == (10000, 1)\n",
        "\n",
        "assert len(np.unique(y_train)) == 100"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e589bead",
      "metadata": {
        "id": "e589bead"
      },
      "source": [
        "Preprocesamos los datos para que estén en el rango [0, 1] y eliminamos el 80% de las etiquetas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "aa77ecd0",
      "metadata": {
        "id": "aa77ecd0"
      },
      "outputs": [],
      "source": [
        "y_train = y_train.reshape(-1)\n",
        "y_test = y_test.reshape(-1)\n",
        "\n",
        "# Normalizamos los datos\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# Eliminamos el 80% de las etiquetas\n",
        "np.random.seed(125)\n",
        "p = np.random.rand(len(y_train))\n",
        "unlabelled_data = x_train[p > 0.2]\n",
        "train_data = x_train[p <= 0.2]\n",
        "train_label = y_train[p <= 0.2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "0a6398d7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a6398d7",
        "outputId": "09d00491-170e-4f01-b485-ecd47e88febe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimensiones de train_data (10080, 32, 32, 3)\n",
            "Dimensiones de unlabelled_data: (39920, 32, 32, 3)\n",
            "Dimensiones de label_data: (10080,)\n",
            "Número de clases: 100\n"
          ]
        }
      ],
      "source": [
        "# Comprobamos las dimensiones\n",
        "print(\"Dimensiones de train_data\", train_data.shape)\n",
        "print(\"Dimensiones de unlabelled_data:\", unlabelled_data.shape)\n",
        "print(\"Dimensiones de label_data:\", train_label.shape)\n",
        "print(\"Número de clases:\", len(np.unique(train_label)))\n",
        "\n",
        "# Constantes\n",
        "INPUT_SHAPE = (32, 32, 3)\n",
        "NUM_CLASES = len(np.unique(train_label))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "caa206d1",
      "metadata": {
        "id": "caa206d1"
      },
      "source": [
        "### Modelo 1: Modelo convolucional sobre datos etiquetados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4eb3c21a",
      "metadata": {
        "id": "4eb3c21a"
      },
      "outputs": [],
      "source": [
        "NUM_CLASES = len(np.unique(train_label))\n",
        "INPUT_SHAPE = (32, 32, 3)\n",
        "\n",
        "class ModeloCNNEtiquetados:\n",
        "\n",
        "    def __init__(self, input_shape, num_clases):\n",
        "\n",
        "        input_layer = layers.Input(shape=input_shape)\n",
        "        x = layers.Conv2D(16, (3, 3), activation='relu')(input_layer)\n",
        "        x = layers.Conv2D(32, (3, 3), activation='relu')(x)\n",
        "        x = layers.MaxPooling2D((2, 2))(x)\n",
        "        x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
        "        x = layers.MaxPooling2D((2, 2))(x)\n",
        "        x = layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
        "        x = layers.MaxPooling2D((2, 2))(x)\n",
        "        x = layers.Flatten()(x)\n",
        "        output_layer = layers.Dense(num_clases, activation='softmax')(x)\n",
        "\n",
        "        self.model = models.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "        self.model.compile(optimizer=optimizers.Adam(),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "    def fit(self, X, y, batch_size=128 , epochs=100, sample_weight=None):\n",
        "        self.model.fit(X, y, batch_size=batch_size, epochs=epochs, sample_weight=sample_weight)\n",
        "\n",
        "    def summary(self):\n",
        "        self.model.summary()\n",
        "\n",
        "    def predict(self, X):\n",
        "        pred = self.model.predict(X)\n",
        "        pred = np.argmax(pred, axis=1)\n",
        "        return pred\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        return self.model.predict(X)\n",
        "\n",
        "    def score(self, X, y):\n",
        "        loss, acc = self.model.evaluate(X, y, verbose=0)\n",
        "        return acc\n",
        "\n",
        "    def __del__(self):\n",
        "        del self.model\n",
        "        tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "191e362c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "191e362c",
        "outputId": "3915255a-f757-41e7-f766-278f22cedbff"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">51,300</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │           \u001b[38;5;34m448\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m4,640\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m51,300\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">148,740</span> (581.02 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m148,740\u001b[0m (581.02 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">148,740</span> (581.02 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m148,740\u001b[0m (581.02 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.0138 - loss: 4.5776\n",
            "Epoch 2/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.0458 - loss: 4.2471\n",
            "Epoch 3/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1123 - loss: 3.8704\n",
            "Epoch 4/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.1412 - loss: 3.6189\n",
            "Epoch 5/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1792 - loss: 3.4252\n",
            "Epoch 6/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.2115 - loss: 3.2621\n",
            "Epoch 7/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.2506 - loss: 3.0986\n",
            "Epoch 8/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2662 - loss: 2.9743\n",
            "Epoch 9/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2877 - loss: 2.8539\n",
            "Epoch 10/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3134 - loss: 2.7381\n",
            "Epoch 11/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3344 - loss: 2.6328\n",
            "Epoch 12/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3640 - loss: 2.4959\n",
            "Epoch 13/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3821 - loss: 2.3976\n",
            "Epoch 14/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4204 - loss: 2.2628\n",
            "Epoch 15/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4374 - loss: 2.1745\n",
            "Epoch 16/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4592 - loss: 2.0842\n",
            "Epoch 17/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4768 - loss: 1.9909\n",
            "Epoch 18/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5031 - loss: 1.8735\n",
            "Epoch 19/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5164 - loss: 1.8110\n",
            "Epoch 20/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5397 - loss: 1.7240\n",
            "Epoch 21/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5509 - loss: 1.6775\n",
            "Epoch 22/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5784 - loss: 1.5509\n",
            "Epoch 23/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5936 - loss: 1.4815\n",
            "Epoch 24/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6262 - loss: 1.3525\n",
            "Epoch 25/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6381 - loss: 1.3015\n",
            "Epoch 26/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6581 - loss: 1.2248\n",
            "Epoch 27/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6815 - loss: 1.1417\n",
            "Epoch 28/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6868 - loss: 1.1093\n",
            "Epoch 29/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7191 - loss: 1.0107\n",
            "Epoch 30/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7244 - loss: 0.9579\n",
            "Epoch 31/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7503 - loss: 0.8888\n",
            "Epoch 32/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7672 - loss: 0.8240\n",
            "Epoch 33/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7814 - loss: 0.7813\n",
            "Epoch 34/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7900 - loss: 0.7298\n",
            "Epoch 35/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7994 - loss: 0.6967\n",
            "Epoch 36/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8313 - loss: 0.5929\n",
            "Epoch 37/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8319 - loss: 0.5754\n",
            "Epoch 38/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8493 - loss: 0.5288\n",
            "Epoch 39/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8640 - loss: 0.4622\n",
            "Epoch 40/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8771 - loss: 0.4331\n",
            "Epoch 41/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8867 - loss: 0.4083\n",
            "Epoch 42/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8938 - loss: 0.3683\n",
            "Epoch 43/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8910 - loss: 0.3643\n",
            "Epoch 44/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9150 - loss: 0.2974\n",
            "Epoch 45/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9216 - loss: 0.2751\n",
            "Epoch 46/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9182 - loss: 0.2921\n",
            "Epoch 47/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9289 - loss: 0.2479\n",
            "Epoch 48/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9415 - loss: 0.2126\n",
            "Epoch 49/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9345 - loss: 0.2235\n",
            "Epoch 50/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9456 - loss: 0.1805\n",
            "Epoch 51/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9612 - loss: 0.1489\n",
            "Epoch 52/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9566 - loss: 0.1510\n",
            "Epoch 53/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9308 - loss: 0.2149\n",
            "Epoch 54/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9257 - loss: 0.2369\n",
            "Epoch 55/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9571 - loss: 0.1476\n",
            "Epoch 56/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9517 - loss: 0.1611\n",
            "Epoch 57/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9635 - loss: 0.1167\n",
            "Epoch 58/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9623 - loss: 0.1303\n",
            "Epoch 59/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9526 - loss: 0.1554\n",
            "Epoch 60/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9265 - loss: 0.2279\n",
            "Epoch 61/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9485 - loss: 0.1602\n",
            "Epoch 62/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9734 - loss: 0.0956\n",
            "Epoch 63/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9822 - loss: 0.0635\n",
            "Epoch 64/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9910 - loss: 0.0447\n",
            "Epoch 65/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9947 - loss: 0.0325\n",
            "Epoch 66/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9952 - loss: 0.0288\n",
            "Epoch 67/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9958 - loss: 0.0208\n",
            "Epoch 68/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9981 - loss: 0.0135\n",
            "Epoch 69/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9985 - loss: 0.0169\n",
            "Epoch 70/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9976 - loss: 0.0145\n",
            "Epoch 71/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9992 - loss: 0.0099\n",
            "Epoch 72/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9988 - loss: 0.0071\n",
            "Epoch 73/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9997 - loss: 0.0065\n",
            "Epoch 74/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 0.0047\n",
            "Epoch 75/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9989 - loss: 0.0082\n",
            "Epoch 76/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9938 - loss: 0.0248\n",
            "Epoch 77/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7549 - loss: 0.9574\n",
            "Epoch 78/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8381 - loss: 0.5044\n",
            "Epoch 79/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9410 - loss: 0.1923\n",
            "Epoch 80/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9652 - loss: 0.1147\n",
            "Epoch 81/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9823 - loss: 0.0640\n",
            "Epoch 82/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9944 - loss: 0.0307\n",
            "Epoch 83/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9983 - loss: 0.0183\n",
            "Epoch 84/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9993 - loss: 0.0095\n",
            "Epoch 85/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 0.0054\n",
            "Epoch 86/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0052\n",
            "Epoch 87/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9996 - loss: 0.0107\n",
            "Epoch 88/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0041\n",
            "Epoch 89/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 0.0052\n",
            "Epoch 90/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 0.0072\n",
            "Epoch 91/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0032\n",
            "Epoch 92/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9998 - loss: 0.0060\n",
            "Epoch 93/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9996 - loss: 0.0088\n",
            "Epoch 94/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0026\n",
            "Epoch 95/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9990 - loss: 0.0084\n",
            "Epoch 96/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9331 - loss: 0.2266\n",
            "Epoch 97/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7931 - loss: 0.7021\n",
            "Epoch 98/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8962 - loss: 0.3293\n",
            "Epoch 99/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9574 - loss: 0.1338\n",
            "Epoch 100/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9820 - loss: 0.0656\n"
          ]
        }
      ],
      "source": [
        "# Creamos el modelo\n",
        "model = ModeloCNNEtiquetados(INPUT_SHAPE, NUM_CLASES)\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(train_data, train_label,\n",
        "                    epochs=100, batch_size=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47095be9",
      "metadata": {
        "id": "47095be9"
      },
      "source": [
        "Evaluamos en el conjunto de train y en el conjunto de test:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56bf95e8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56bf95e8",
        "outputId": "21d1b6f0-0c9f-4d41-ef8f-1c8585bfdea1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train accuracy: 0.99296\n",
            "Test accuracy: 0.2279\n"
          ]
        }
      ],
      "source": [
        "# Evaluamos en train\n",
        "train_acc = model.score(train_data, train_label)\n",
        "print('Train accuracy:', round(train_acc, 5))\n",
        "\n",
        "# Evaluamos en test\n",
        "test_acc = model.score(x_test, y_test)\n",
        "print('Test accuracy:', round(test_acc, 5))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d0f82ae",
      "metadata": {
        "id": "7d0f82ae"
      },
      "source": [
        "**<u>Cuestiones:</u>**\n",
        "\n",
        "\n",
        "1. **¿Qué red has escogido? ¿Cómo la has entrenado?**\n",
        "\n",
        "    Creamos un modelo convolucional de 4 capas *Conv2D* y 3 capas de pooling. Las capas convolucionales de 16, 32, 64 y 128 neuronas respectivamente, aumentan el número de canales mientras reducen el tamaño de estes y cada una de las capas de *MaxPooling* nos ayudará a reducir el número de parámetros entrenables. Por último se aplica una capa *flatten* y se obtiene la salida predicha con una *Dense* de 100 neuronas (una por cada clase)\n",
        "    con función de activación *softmax*.\n",
        "\n",
        "    Para el entrenamiento se utilizan los conjuntos de *train_data* y *train_label*s, con un tamaño de batch de 128 y 100 epochs. La función de pérdida utilizada es *categorical_crossentropy* y el optimizador *adam*.\n",
        "\n",
        "2. **¿Cuál es la precisión del modelo en entrenamiento? ¿Y en test?**\n",
        "    \n",
        "    La precisión en entrenamiento es de $0.99296$ mientras que en el conjunto de test es de $0.2279$.\n",
        "\n",
        "3. **¿Qué conclusiones sacas de los resultados del punto anterior?**\n",
        "\n",
        "    Está claro que el modelo esta sobreentrenando. Esto seguramente se deba a que estamos utilizando una red muy compleja para un conjunto de datos reducido (recordamos que solo estamos utilizando el 20% etiquetado de los datos originales). Nuestro modelo no está generalizando bien."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e188942",
      "metadata": {
        "id": "8e188942"
      },
      "source": [
        "### Modelo 2: Autoaprendizaje"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37cf9c43",
      "metadata": {
        "id": "37cf9c43"
      },
      "source": [
        "Implementamos el algoritmo de autoaprendizaje:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5edbb0d7",
      "metadata": {
        "id": "5edbb0d7"
      },
      "source": [
        "- **self_training** *(model, x_train, y_train, unlabeled_data, thresh, train_epochs)*\n",
        "\n",
        "    1. $train\\_data, train\\_label \\leftarrow x\\_train, y\\_train$\n",
        "    1. **Desde** $n = 1 .. train\\_epochs$ **hacer**\n",
        "        1. Instancia un nuevo *model* y entrénalo usando las variables *train\\_data* y *train\\_label*\n",
        "        2. $y\\_pred \\leftarrow model(unlabeled\\_data)$\n",
        "        3. $y\\_class, y\\_value \\leftarrow $ Clase ganadora en *y_pred* con su valor\n",
        "        4. $train\\_data, train\\_label \\leftarrow x\\_train, y\\_train$\n",
        "        5. **Para cada elemento** (x_u, y_c, y_v) **de la tupla** ($unlabeled\\_data$, $y\\_class$, $y\\_value$)\n",
        "            1. **Si** $y\\_v > thresh$ **entonces**\n",
        "                1. Añadimos $x\\_u$ e $y\\_c$ a $train\\_data$ y $train\\_label$, respectivamente.\n",
        "    4. Devolvemos el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fedf9e89",
      "metadata": {
        "id": "fedf9e89"
      },
      "outputs": [],
      "source": [
        "def self_training_v2(model_creator, x_train, y_train, unlabeled_data, x_test, y_test, thresh=0.8, train_epochs=3):\n",
        "    # Creamos una copia de los datos no etiquetados para no modificar el original\n",
        "    train_data = x_train.copy()\n",
        "    train_label = y_train.copy()\n",
        "\n",
        "    # Pesos iniciales para los datos etiquetados\n",
        "    weights = np.ones(len(train_label))\n",
        "\n",
        "    for i in range(train_epochs):\n",
        "        model = model_creator()\n",
        "        if i==0:\n",
        "            model.summary()\n",
        "        # Entrenamos el modelo con los datos etiquetados y sus pesos\n",
        "        model.fit(train_data, train_label, sample_weight=weights)\n",
        "\n",
        "        # Predecimos las probabilidades en el conjunto no etiquetado\n",
        "        y_pred = model.predict_proba(unlabeled_data)\n",
        "        y_class = np.argmax(y_pred, axis=1)\n",
        "        y_value = np.max(y_pred, axis=1)\n",
        "\n",
        "        # Seleccionamos solo aquellos con probabilidad mayor o igual al umbral\n",
        "        indexes = np.where(y_value >= thresh)[0]\n",
        "\n",
        "        # Añadimos las muestras seleccionadas al conjunto de entrenamiento\n",
        "        new_data = unlabeled_data[indexes]\n",
        "        new_labels = y_class[indexes]\n",
        "\n",
        "        # Peso proporcional a la certeza de la predicción\n",
        "        new_weights = y_value[indexes]\n",
        "\n",
        "        train_data = np.concatenate((train_data, new_data))\n",
        "        train_label = np.concatenate((train_label, new_labels))\n",
        "        weights = np.concatenate((weights, new_weights))\n",
        "\n",
        "        # Eliminamos los datos etiquetados del conjunto no etiquetado\n",
        "        unlabeled_data = np.delete(unlabeled_data, indexes, axis=0)\n",
        "\n",
        "        # Evaluamos en el conjunto de test\n",
        "        print(\"Epoch:\", i+1, \"Accuracy:\", model.score(x_test, y_test))\n",
        "        print(\"Número de elementos en el conjunto etiquetado:\", len(train_label))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "577a6198",
      "metadata": {
        "id": "577a6198"
      },
      "source": [
        "Utilizamos el modelo clasificador anterior:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cfdb96d",
      "metadata": {
        "id": "8cfdb96d"
      },
      "outputs": [],
      "source": [
        "model_func = lambda: ModeloCNNEtiquetados(INPUT_SHAPE, NUM_CLASES)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95997a4e",
      "metadata": {
        "id": "95997a4e"
      },
      "source": [
        "Entrenamos el modelo de autoaprendizaje:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db8abc39",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "db8abc39",
        "outputId": "6023559c-0bd9-476c-c547-ded37c10a00b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">51,300</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │           \u001b[38;5;34m448\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m4,640\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_6 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_7 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_8 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m51,300\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">148,740</span> (581.02 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m148,740\u001b[0m (581.02 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">148,740</span> (581.02 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m148,740\u001b[0m (581.02 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.0164 - loss: 4.5457\n",
            "Epoch 2/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.0531 - loss: 4.1922\n",
            "Epoch 3/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.1087 - loss: 3.8750\n",
            "Epoch 4/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1520 - loss: 3.6110\n",
            "Epoch 5/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1883 - loss: 3.4273\n",
            "Epoch 6/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2209 - loss: 3.2400\n",
            "Epoch 7/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2471 - loss: 3.1254\n",
            "Epoch 8/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2744 - loss: 2.9387\n",
            "Epoch 9/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.2927 - loss: 2.8608\n",
            "Epoch 10/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3277 - loss: 2.6794\n",
            "Epoch 11/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3525 - loss: 2.5675\n",
            "Epoch 12/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3784 - loss: 2.4452\n",
            "Epoch 13/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.3974 - loss: 2.3428\n",
            "Epoch 14/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4241 - loss: 2.2527\n",
            "Epoch 15/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4464 - loss: 2.1317\n",
            "Epoch 16/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4719 - loss: 2.0098\n",
            "Epoch 17/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4958 - loss: 1.9014\n",
            "Epoch 18/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5076 - loss: 1.8578\n",
            "Epoch 19/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5331 - loss: 1.7508\n",
            "Epoch 20/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5618 - loss: 1.6105\n",
            "Epoch 21/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5929 - loss: 1.4997\n",
            "Epoch 22/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6139 - loss: 1.4180\n",
            "Epoch 23/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6327 - loss: 1.3414\n",
            "Epoch 24/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6571 - loss: 1.2438\n",
            "Epoch 25/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6668 - loss: 1.2210\n",
            "Epoch 26/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6888 - loss: 1.1183\n",
            "Epoch 27/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7049 - loss: 1.0619\n",
            "Epoch 28/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7328 - loss: 0.9569\n",
            "Epoch 29/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7442 - loss: 0.9183\n",
            "Epoch 30/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7706 - loss: 0.8079\n",
            "Epoch 31/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7819 - loss: 0.7727\n",
            "Epoch 32/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7936 - loss: 0.7120\n",
            "Epoch 33/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8134 - loss: 0.6598\n",
            "Epoch 34/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8325 - loss: 0.5892\n",
            "Epoch 35/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8450 - loss: 0.5369\n",
            "Epoch 36/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8631 - loss: 0.4940\n",
            "Epoch 37/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8646 - loss: 0.4669\n",
            "Epoch 38/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8813 - loss: 0.4133\n",
            "Epoch 39/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8851 - loss: 0.4020\n",
            "Epoch 40/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9035 - loss: 0.3311\n",
            "Epoch 41/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9072 - loss: 0.3471\n",
            "Epoch 42/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9280 - loss: 0.2545\n",
            "Epoch 43/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9298 - loss: 0.2541\n",
            "Epoch 44/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9249 - loss: 0.2589\n",
            "Epoch 45/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9298 - loss: 0.2343\n",
            "Epoch 46/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9413 - loss: 0.1998\n",
            "Epoch 47/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9450 - loss: 0.1941\n",
            "Epoch 48/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9494 - loss: 0.1730\n",
            "Epoch 49/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9460 - loss: 0.1883\n",
            "Epoch 50/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9444 - loss: 0.1793\n",
            "Epoch 51/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9590 - loss: 0.1476\n",
            "Epoch 52/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9496 - loss: 0.1627\n",
            "Epoch 53/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9496 - loss: 0.1612\n",
            "Epoch 54/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9454 - loss: 0.1692\n",
            "Epoch 55/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9591 - loss: 0.1337\n",
            "Epoch 56/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9482 - loss: 0.1687\n",
            "Epoch 57/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9405 - loss: 0.1685\n",
            "Epoch 58/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9354 - loss: 0.1941\n",
            "Epoch 59/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9527 - loss: 0.1470\n",
            "Epoch 60/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9553 - loss: 0.1409\n",
            "Epoch 61/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9546 - loss: 0.1361\n",
            "Epoch 62/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9709 - loss: 0.0959\n",
            "Epoch 63/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9846 - loss: 0.0637\n",
            "Epoch 64/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9829 - loss: 0.0549\n",
            "Epoch 65/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9923 - loss: 0.0348\n",
            "Epoch 66/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9950 - loss: 0.0305\n",
            "Epoch 67/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9955 - loss: 0.0231\n",
            "Epoch 68/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9959 - loss: 0.0236\n",
            "Epoch 69/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9960 - loss: 0.0195\n",
            "Epoch 70/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9980 - loss: 0.0138\n",
            "Epoch 71/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9963 - loss: 0.0212\n",
            "Epoch 72/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9985 - loss: 0.0118\n",
            "Epoch 73/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9339 - loss: 0.2162\n",
            "Epoch 74/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7923 - loss: 0.7169\n",
            "Epoch 75/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9025 - loss: 0.2847\n",
            "Epoch 76/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9662 - loss: 0.1130\n",
            "Epoch 77/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9889 - loss: 0.0538\n",
            "Epoch 78/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9977 - loss: 0.0208\n",
            "Epoch 79/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9994 - loss: 0.0084\n",
            "Epoch 80/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0061\n",
            "Epoch 81/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 0.0054\n",
            "Epoch 82/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9998 - loss: 0.0063\n",
            "Epoch 83/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0037\n",
            "Epoch 84/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0032\n",
            "Epoch 85/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0029\n",
            "Epoch 86/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 0.0040\n",
            "Epoch 87/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9996 - loss: 0.0070\n",
            "Epoch 88/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 0.0033\n",
            "Epoch 89/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 0.0043\n",
            "Epoch 90/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9997 - loss: 0.0076\n",
            "Epoch 91/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 0.0022\n",
            "Epoch 92/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 0.0047\n",
            "Epoch 93/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 0.0033\n",
            "Epoch 94/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9961 - loss: 0.0177\n",
            "Epoch 95/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7840 - loss: 0.8484\n",
            "Epoch 96/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8637 - loss: 0.4370\n",
            "Epoch 97/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9274 - loss: 0.2157\n",
            "Epoch 98/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9694 - loss: 0.1046\n",
            "Epoch 99/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9922 - loss: 0.0393\n",
            "Epoch 100/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9981 - loss: 0.0152\n",
            "\u001b[1m1248/1248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
            "Epoch: 1 Accuracy: 0.22660000622272491\n",
            "Número de elementos en el conjunto etiquetado: 36944\n",
            "Epoch 1/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.0575 - loss: 4.1362\n",
            "Epoch 2/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.2284 - loss: 3.1242\n",
            "Epoch 3/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3002 - loss: 2.7297\n",
            "Epoch 4/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3404 - loss: 2.4852\n",
            "Epoch 5/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3740 - loss: 2.3337\n",
            "Epoch 6/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3976 - loss: 2.2003\n",
            "Epoch 7/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4302 - loss: 2.0781\n",
            "Epoch 8/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4384 - loss: 1.9941\n",
            "Epoch 9/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4593 - loss: 1.9141\n",
            "Epoch 10/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4780 - loss: 1.8355\n",
            "Epoch 11/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4954 - loss: 1.7636\n",
            "Epoch 12/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5157 - loss: 1.6911\n",
            "Epoch 13/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5279 - loss: 1.6358\n",
            "Epoch 14/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5448 - loss: 1.5678\n",
            "Epoch 15/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5497 - loss: 1.5420\n",
            "Epoch 16/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5729 - loss: 1.4585\n",
            "Epoch 17/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5837 - loss: 1.4079\n",
            "Epoch 18/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5955 - loss: 1.3644\n",
            "Epoch 19/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6082 - loss: 1.3196\n",
            "Epoch 20/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6170 - loss: 1.2894\n",
            "Epoch 21/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6321 - loss: 1.2357\n",
            "Epoch 22/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6415 - loss: 1.2001\n",
            "Epoch 23/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6428 - loss: 1.1769\n",
            "Epoch 24/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6495 - loss: 1.1506\n",
            "Epoch 25/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6635 - loss: 1.1077\n",
            "Epoch 26/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6730 - loss: 1.0712\n",
            "Epoch 27/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6776 - loss: 1.0412\n",
            "Epoch 28/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6934 - loss: 0.9983\n",
            "Epoch 29/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6990 - loss: 0.9722\n",
            "Epoch 30/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7088 - loss: 0.9439\n",
            "Epoch 31/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7147 - loss: 0.9130\n",
            "Epoch 32/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7244 - loss: 0.8809\n",
            "Epoch 33/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7321 - loss: 0.8638\n",
            "Epoch 34/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7448 - loss: 0.8166\n",
            "Epoch 35/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7451 - loss: 0.8052\n",
            "Epoch 36/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7491 - loss: 0.7861\n",
            "Epoch 37/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7679 - loss: 0.7336\n",
            "Epoch 38/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7681 - loss: 0.7229\n",
            "Epoch 39/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7768 - loss: 0.7041\n",
            "Epoch 40/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7730 - loss: 0.7025\n",
            "Epoch 41/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7790 - loss: 0.6755\n",
            "Epoch 42/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7960 - loss: 0.6385\n",
            "Epoch 43/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7924 - loss: 0.6315\n",
            "Epoch 44/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8022 - loss: 0.6028\n",
            "Epoch 45/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8046 - loss: 0.5868\n",
            "Epoch 46/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8130 - loss: 0.5621\n",
            "Epoch 47/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8120 - loss: 0.5654\n",
            "Epoch 48/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8237 - loss: 0.5293\n",
            "Epoch 49/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8211 - loss: 0.5330\n",
            "Epoch 50/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8295 - loss: 0.5052\n",
            "Epoch 51/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8335 - loss: 0.4999\n",
            "Epoch 52/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8414 - loss: 0.4692\n",
            "Epoch 53/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8470 - loss: 0.4550\n",
            "Epoch 54/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8497 - loss: 0.4441\n",
            "Epoch 55/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8582 - loss: 0.4278\n",
            "Epoch 56/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8495 - loss: 0.4379\n",
            "Epoch 57/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8614 - loss: 0.4071\n",
            "Epoch 58/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8643 - loss: 0.3940\n",
            "Epoch 59/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8667 - loss: 0.3910\n",
            "Epoch 60/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8750 - loss: 0.3674\n",
            "Epoch 61/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8749 - loss: 0.3682\n",
            "Epoch 62/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8746 - loss: 0.3681\n",
            "Epoch 63/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8728 - loss: 0.3597\n",
            "Epoch 64/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8852 - loss: 0.3263\n",
            "Epoch 65/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8859 - loss: 0.3314\n",
            "Epoch 66/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8866 - loss: 0.3230\n",
            "Epoch 67/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8984 - loss: 0.2910\n",
            "Epoch 68/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8916 - loss: 0.3068\n",
            "Epoch 69/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8900 - loss: 0.3132\n",
            "Epoch 70/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8927 - loss: 0.3020\n",
            "Epoch 71/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9018 - loss: 0.2830\n",
            "Epoch 72/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8977 - loss: 0.2927\n",
            "Epoch 73/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8977 - loss: 0.2887\n",
            "Epoch 74/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9066 - loss: 0.2673\n",
            "Epoch 75/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9024 - loss: 0.2696\n",
            "Epoch 76/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9072 - loss: 0.2612\n",
            "Epoch 77/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8967 - loss: 0.2984\n",
            "Epoch 78/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9072 - loss: 0.2603\n",
            "Epoch 79/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9134 - loss: 0.2404\n",
            "Epoch 80/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9187 - loss: 0.2331\n",
            "Epoch 81/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9042 - loss: 0.2650\n",
            "Epoch 82/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9112 - loss: 0.2465\n",
            "Epoch 83/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9214 - loss: 0.2225\n",
            "Epoch 84/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9066 - loss: 0.2564\n",
            "Epoch 85/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9162 - loss: 0.2339\n",
            "Epoch 86/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9193 - loss: 0.2231\n",
            "Epoch 87/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9231 - loss: 0.2098\n",
            "Epoch 88/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9269 - loss: 0.2041\n",
            "Epoch 89/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9158 - loss: 0.2315\n",
            "Epoch 90/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9230 - loss: 0.2182\n",
            "Epoch 91/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9212 - loss: 0.2148\n",
            "Epoch 92/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9289 - loss: 0.1993\n",
            "Epoch 93/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9150 - loss: 0.2360\n",
            "Epoch 94/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9347 - loss: 0.1841\n",
            "Epoch 95/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9174 - loss: 0.2274\n",
            "Epoch 96/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9298 - loss: 0.1946\n",
            "Epoch 97/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9233 - loss: 0.2113\n",
            "Epoch 98/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9240 - loss: 0.2117\n",
            "Epoch 99/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9342 - loss: 0.1806\n",
            "Epoch 100/100\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9190 - loss: 0.2236\n",
            "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Epoch: 2 Accuracy: 0.2168000042438507\n",
            "Número de elementos en el conjunto etiquetado: 46134\n",
            "Epoch 1/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.0696 - loss: 4.0357\n",
            "Epoch 2/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.2490 - loss: 2.9676\n",
            "Epoch 3/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3128 - loss: 2.5940\n",
            "Epoch 4/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3551 - loss: 2.3860\n",
            "Epoch 5/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3865 - loss: 2.2301\n",
            "Epoch 6/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4026 - loss: 2.1251\n",
            "Epoch 7/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4272 - loss: 2.0213\n",
            "Epoch 8/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4449 - loss: 1.9363\n",
            "Epoch 9/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4686 - loss: 1.8658\n",
            "Epoch 10/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4797 - loss: 1.7881\n",
            "Epoch 11/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4941 - loss: 1.7268\n",
            "Epoch 12/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5089 - loss: 1.6736\n",
            "Epoch 13/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5256 - loss: 1.6124\n",
            "Epoch 14/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5416 - loss: 1.5584\n",
            "Epoch 15/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5514 - loss: 1.5209\n",
            "Epoch 16/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5630 - loss: 1.4650\n",
            "Epoch 17/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5723 - loss: 1.4359\n",
            "Epoch 18/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5814 - loss: 1.3914\n",
            "Epoch 19/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5994 - loss: 1.3330\n",
            "Epoch 20/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6000 - loss: 1.3240\n",
            "Epoch 21/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6162 - loss: 1.2636\n",
            "Epoch 22/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6227 - loss: 1.2305\n",
            "Epoch 23/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6329 - loss: 1.1955\n",
            "Epoch 24/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6486 - loss: 1.1535\n",
            "Epoch 25/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6528 - loss: 1.1310\n",
            "Epoch 26/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6589 - loss: 1.1047\n",
            "Epoch 27/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6652 - loss: 1.0813\n",
            "Epoch 28/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6732 - loss: 1.0470\n",
            "Epoch 29/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6804 - loss: 1.0102\n",
            "Epoch 30/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6955 - loss: 0.9765\n",
            "Epoch 31/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7011 - loss: 0.9558\n",
            "Epoch 32/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7029 - loss: 0.9415\n",
            "Epoch 33/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7158 - loss: 0.9069\n",
            "Epoch 34/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7222 - loss: 0.8789\n",
            "Epoch 35/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7255 - loss: 0.8584\n",
            "Epoch 36/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7250 - loss: 0.8516\n",
            "Epoch 37/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7404 - loss: 0.8102\n",
            "Epoch 38/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7511 - loss: 0.7809\n",
            "Epoch 39/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7529 - loss: 0.7633\n",
            "Epoch 40/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7584 - loss: 0.7492\n",
            "Epoch 41/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7566 - loss: 0.7496\n",
            "Epoch 42/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7688 - loss: 0.7123\n",
            "Epoch 43/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7695 - loss: 0.7089\n",
            "Epoch 44/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7822 - loss: 0.6708\n",
            "Epoch 45/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7807 - loss: 0.6692\n",
            "Epoch 46/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7884 - loss: 0.6474\n",
            "Epoch 47/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7882 - loss: 0.6336\n",
            "Epoch 48/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7983 - loss: 0.6146\n",
            "Epoch 49/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8014 - loss: 0.6017\n",
            "Epoch 50/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8073 - loss: 0.5773\n",
            "Epoch 51/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8038 - loss: 0.5863\n",
            "Epoch 52/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8150 - loss: 0.5536\n",
            "Epoch 53/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8131 - loss: 0.5470\n",
            "Epoch 54/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8204 - loss: 0.5337\n",
            "Epoch 55/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8247 - loss: 0.5153\n",
            "Epoch 56/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8255 - loss: 0.5102\n",
            "Epoch 57/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8347 - loss: 0.4916\n",
            "Epoch 58/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8341 - loss: 0.4848\n",
            "Epoch 59/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8342 - loss: 0.4815\n",
            "Epoch 60/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8452 - loss: 0.4539\n",
            "Epoch 61/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8460 - loss: 0.4473\n",
            "Epoch 62/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8418 - loss: 0.4514\n",
            "Epoch 63/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8507 - loss: 0.4302\n",
            "Epoch 64/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8522 - loss: 0.4264\n",
            "Epoch 65/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8510 - loss: 0.4222\n",
            "Epoch 66/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8609 - loss: 0.4040\n",
            "Epoch 67/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8626 - loss: 0.3958\n",
            "Epoch 68/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8672 - loss: 0.3817\n",
            "Epoch 69/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8659 - loss: 0.3791\n",
            "Epoch 70/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8687 - loss: 0.3723\n",
            "Epoch 71/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8661 - loss: 0.3711\n",
            "Epoch 72/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8806 - loss: 0.3489\n",
            "Epoch 73/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8743 - loss: 0.3549\n",
            "Epoch 74/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8768 - loss: 0.3492\n",
            "Epoch 75/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8801 - loss: 0.3321\n",
            "Epoch 76/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8820 - loss: 0.3292\n",
            "Epoch 77/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8856 - loss: 0.3234\n",
            "Epoch 78/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8906 - loss: 0.3060\n",
            "Epoch 79/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8802 - loss: 0.3290\n",
            "Epoch 80/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8879 - loss: 0.3079\n",
            "Epoch 81/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8908 - loss: 0.3015\n",
            "Epoch 82/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8866 - loss: 0.3126\n",
            "Epoch 83/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8973 - loss: 0.2843\n",
            "Epoch 84/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8882 - loss: 0.3082\n",
            "Epoch 85/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8826 - loss: 0.3217\n",
            "Epoch 86/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9001 - loss: 0.2773\n",
            "Epoch 87/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8972 - loss: 0.2825\n",
            "Epoch 88/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8965 - loss: 0.2844\n",
            "Epoch 89/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9047 - loss: 0.2627\n",
            "Epoch 90/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8989 - loss: 0.2750\n",
            "Epoch 91/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9003 - loss: 0.2709\n",
            "Epoch 92/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9035 - loss: 0.2655\n",
            "Epoch 93/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9025 - loss: 0.2726\n",
            "Epoch 94/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9011 - loss: 0.2744\n",
            "Epoch 95/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9160 - loss: 0.2285\n",
            "Epoch 96/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9014 - loss: 0.2695\n",
            "Epoch 97/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8997 - loss: 0.2689\n",
            "Epoch 98/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9111 - loss: 0.2413\n",
            "Epoch 99/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9088 - loss: 0.2499\n",
            "Epoch 100/100\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9087 - loss: 0.2524\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "Epoch: 3 Accuracy: 0.21649999916553497\n",
            "Número de elementos en el conjunto etiquetado: 48646\n"
          ]
        }
      ],
      "source": [
        "model = self_training_v2(model_func, train_data, train_label, unlabelled_data, x_test, y_test, train_epochs=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "368d7a0c",
      "metadata": {
        "id": "368d7a0c"
      },
      "source": [
        "Evaluamos en el conjunto de entrenamiento y en el de test:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d4c46d7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d4c46d7",
        "outputId": "b6847371-42d5-4717-9675-b526a625f63e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train accuracy: 0.91121\n",
            "Test accuracy: 0.2165\n"
          ]
        }
      ],
      "source": [
        "# Evaluamos en train\n",
        "train_acc = model.score(train_data, train_label)\n",
        "print('Train accuracy:', round(train_acc, 5))\n",
        "\n",
        "# Evaluamos en test\n",
        "test_acc = model.score(x_test, y_test)\n",
        "print('Test accuracy:', round(test_acc, 5))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd41ada9",
      "metadata": {
        "id": "bd41ada9"
      },
      "source": [
        "    \n",
        "- **<u>Cuestiones:</u>**\n",
        "\n",
        "    1. **¿Qué parámetros has definido para el entrenamiento?**\n",
        "\n",
        "        - *train\\_epochs*: 3 (Número de épocas para el self-training)\n",
        "        - *thresh*: 0.8 (Umbral de confianza para añadir ejemplos no etiquetados al conjunto de entrenamiento)\n",
        "        - *batch\\_size*: 128 (Tamaño del batch para el entrenamiento del modelo)\n",
        "        - *epochs*: 100 (Número de épocas para el entrenamiento del modelo)\n",
        "\n",
        "          Al igual que en el modelo anterior, la función de pérdida utilizada es *categorical_crossentropy* y el optimizador *adam*.\n",
        "\n",
        "          Además se utiliza un vector de pesos para ponderar cada ejemplo de entrada en función de su calidad (o certeza). Este vector será 1 para los ejemplos etiquetados y se establecerá según su probabilidad o certeza de pertenencia a la clase para los ejemplos no etiquetados que sean añadidos al conjunto de entrenamiento.\n",
        "\n",
        "    2. **¿Cuál es la precisión del modelo en entrenamiento? ¿Y en test?**\n",
        "\n",
        "        La precisión en entrenamiento es de $0.91121$ mientras que en el conjunto de test es de $0.2165$.\n",
        "    \n",
        "        A la vista de los resultados, el modelo no ha mejorado su precisión en el conjunto de test, aunque sí ha aumentado la cantidad de datos etiquetados.\n",
        "\n",
        "    3. **¿Se mejoran los resultados obtenidos en el ejercicio anterior?**\n",
        "\n",
        "        A la vista de los resultados, las mejoras del modelo de autoaprendizaje no son significativas.\n",
        "\n",
        "    4. **¿Qué conclusiones sacas de los resultados del punto anterior?**\n",
        "\n",
        "        Estamos añadiendo patrones al conjunto de entrenamiento, por lo que reducimos el problema de que nuestro modelo se ajuste para unos pocos datos concretos, sin embargo, a la vista de los resultados de test seguimos sin lograr una buena generalización.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zQUsSRQfD9JG",
      "metadata": {
        "id": "zQUsSRQfD9JG"
      },
      "source": [
        "### Modelo 3: Autoencoder en dos pasos"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PALzP6SWFxJ-",
      "metadata": {
        "id": "PALzP6SWFxJ-"
      },
      "source": [
        "Definimos el autoencoder:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RSdUgjQ2D8zw",
      "metadata": {
        "id": "RSdUgjQ2D8zw"
      },
      "outputs": [],
      "source": [
        "class MiAutoencoder:\n",
        "\n",
        "    def __init__(self, input_shape):\n",
        "        # Input layer\n",
        "        input_layer = layers.Input(shape=input_shape)\n",
        "\n",
        "        # Encoder\n",
        "        x = layers.Conv2D(16, (3, 3), activation='relu')(input_layer)\n",
        "        x = layers.Conv2D(32, (3, 3), activation='relu')(x)\n",
        "        x = layers.MaxPooling2D((2, 2))(x)\n",
        "        x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
        "        x = layers.MaxPooling2D((2, 2))(x)\n",
        "        encoded = layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
        "\n",
        "        # Decoder\n",
        "        x = layers.Conv2DTranspose(128, (3, 3), activation='relu')(encoded)\n",
        "        x = layers.UpSampling2D((2, 2))(x)\n",
        "        x = layers.Conv2DTranspose(64, (3, 3), activation='relu')(x)\n",
        "        x = layers.UpSampling2D((2, 2))(x)\n",
        "        x = layers.Conv2DTranspose(32, (3, 3), activation='relu')(x)\n",
        "        x = layers.Conv2DTranspose(16, (3, 3), activation='relu', padding='same')(x)\n",
        "        decoded = layers.Conv2DTranspose(3, (3, 3), activation='sigmoid')(x)\n",
        "\n",
        "        self.encoder = models.Model(inputs=input_layer, outputs=encoded)\n",
        "\n",
        "        self.autoencoder = models.Model(inputs=input_layer, outputs=decoded)\n",
        "\n",
        "        self.autoencoder.compile(optimizer=optimizers.Adam(),\n",
        "                                   loss=tf.keras.losses.MeanSquaredError())\n",
        "\n",
        "\n",
        "    def fit(self, X, y=None, sample_weight=None):\n",
        "        # Entrenar el autoencoder para que aprenda a reconstruir\n",
        "        self.autoencoder.fit(X, X, batch_size=128, epochs=50, sample_weight=sample_weight)\n",
        "\n",
        "    def summary(self):\n",
        "        self.autoencoder.summary()\n",
        "\n",
        "    def get_encoded_data(self, X):\n",
        "        # Obtener la representación codificada (output del encoder)\n",
        "        return self.encoder.predict(X)\n",
        "\n",
        "    def __del__(self):\n",
        "        # Elimina todos los modelos que hayas creado\n",
        "        tf.keras.backend.clear_session()  # Necesario para liberar la memoria en GPU\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "teW3a0ARF00b",
      "metadata": {
        "id": "teW3a0ARF00b"
      },
      "source": [
        "Definimos el clasificador:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "KGstGWsOF2yf",
      "metadata": {
        "id": "KGstGWsOF2yf"
      },
      "outputs": [],
      "source": [
        "class MiClasificador:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.model = tf.keras.Sequential([\n",
        "            tf.keras.layers.InputLayer(shape=(4, 4, 128)),\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dense(1024, activation='relu'),\n",
        "            tf.keras.layers.Dense(256, activation='relu'),\n",
        "            tf.keras.layers.Dense(128, activation='relu'),\n",
        "            tf.keras.layers.Dense(NUM_CLASES, activation='softmax')\n",
        "        ])\n",
        "\n",
        "        self.model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    def fit(self, X, y, sample_weight=None):\n",
        "        # Entrenar el modelo\n",
        "        self.model.fit(X, y, batch_size=256, epochs=100, sample_weight=sample_weight) # Cambiado a 256 para el ej.6\n",
        "\n",
        "    def predict(self, X):\n",
        "        # Predecir la clase ganadora\n",
        "        return np.argmax(self.model.predict(X), axis=1)\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        # Predecir probabilidades de clase\n",
        "        return self.model.predict(X)\n",
        "\n",
        "    def score(self, X, y):\n",
        "        # Evaluar el modelo\n",
        "        _, acc = self.model.evaluate(X, y, verbose=0)\n",
        "        return acc"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06hfqB1rGZHN",
      "metadata": {
        "id": "06hfqB1rGZHN"
      },
      "source": [
        "Definimos la función del entrenamiento semisupervisado en 2 pasos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "jQuvArFWGcU2",
      "metadata": {
        "id": "jQuvArFWGcU2"
      },
      "outputs": [],
      "source": [
        "def semisupervised_training(autoencoder, classifier, x_train, y_train, unlabeled_data):\n",
        "    # Concatenar los datos y entrenar el autoencoder\n",
        "    all_data = np.concatenate([x_train, unlabeled_data], axis=0)\n",
        "    autoencoder.fit(all_data)\n",
        "    encoded_data = autoencoder.get_encoded_data(x_train)\n",
        "\n",
        "    # Entrenar el clasificador simple\n",
        "    classifier.fit(encoded_data, y_train)\n",
        "\n",
        "    return autoencoder, classifier\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IyHm-Hn4GhTm",
      "metadata": {
        "id": "IyHm-Hn4GhTm"
      },
      "source": [
        "Entrenamos nuestro modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_tJljMHiGgUR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657
        },
        "id": "_tJljMHiGgUR",
        "outputId": "2c073c76-357e-4608-ff0e-edb6e8da90d0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_10\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_10\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_transpose                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ up_sampling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_transpose_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,792</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ up_sampling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_transpose_2              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,464</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_transpose_3              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,624</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_transpose_4              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">435</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │           \u001b[38;5;34m448\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m4,640\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_transpose                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m147,584\u001b[0m │\n",
              "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ up_sampling2d (\u001b[38;5;33mUpSampling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_transpose_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m73,792\u001b[0m │\n",
              "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ up_sampling2d_1 (\u001b[38;5;33mUpSampling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_transpose_2              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │        \u001b[38;5;34m18,464\u001b[0m │\n",
              "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_transpose_3              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │         \u001b[38;5;34m4,624\u001b[0m │\n",
              "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_transpose_4              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │           \u001b[38;5;34m435\u001b[0m │\n",
              "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">342,339</span> (1.31 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m342,339\u001b[0m (1.31 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">342,339</span> (1.31 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m342,339\u001b[0m (1.31 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Crea tu autoencoder y tu clasificador\n",
        "autoencoder = MiAutoencoder(input_shape=INPUT_SHAPE)\n",
        "autoencoder.summary()\n",
        "\n",
        "classifier = MiClasificador()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rHcW8ilFHfdJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHcW8ilFHfdJ",
        "outputId": "6afe9659-a889-4db8-b7ad-83bba65975ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - loss: 0.0324\n",
            "Epoch 2/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0097\n",
            "Epoch 3/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.0078\n",
            "Epoch 4/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0071\n",
            "Epoch 5/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.0067\n",
            "Epoch 6/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.0062\n",
            "Epoch 7/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.0059\n",
            "Epoch 8/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0056\n",
            "Epoch 9/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.0055\n",
            "Epoch 10/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0052\n",
            "Epoch 11/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.0051\n",
            "Epoch 12/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0050\n",
            "Epoch 13/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.0048\n",
            "Epoch 14/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0047\n",
            "Epoch 15/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0046\n",
            "Epoch 16/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0045\n",
            "Epoch 17/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.0045\n",
            "Epoch 18/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.0043\n",
            "Epoch 19/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0043\n",
            "Epoch 20/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0042\n",
            "Epoch 21/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.0041\n",
            "Epoch 22/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0041\n",
            "Epoch 23/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0040\n",
            "Epoch 24/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.0040\n",
            "Epoch 25/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.0039\n",
            "Epoch 26/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0038\n",
            "Epoch 27/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0039\n",
            "Epoch 28/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.0037\n",
            "Epoch 29/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0037\n",
            "Epoch 30/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.0037\n",
            "Epoch 31/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0037\n",
            "Epoch 32/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.0036\n",
            "Epoch 33/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0036\n",
            "Epoch 34/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0036\n",
            "Epoch 35/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 0.0035\n",
            "Epoch 36/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.0035\n",
            "Epoch 37/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.0034\n",
            "Epoch 38/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.0034\n",
            "Epoch 39/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.0034\n",
            "Epoch 40/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.0034\n",
            "Epoch 41/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0034\n",
            "Epoch 42/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.0033\n",
            "Epoch 43/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0033\n",
            "Epoch 44/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - loss: 0.0032\n",
            "Epoch 45/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0032\n",
            "Epoch 46/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.0032\n",
            "Epoch 47/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.0032\n",
            "Epoch 48/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 0.0032\n",
            "Epoch 49/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0032\n",
            "Epoch 50/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.0031\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Epoch 1/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.0189 - loss: 4.6031\n",
            "Epoch 2/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0547 - loss: 4.1873\n",
            "Epoch 3/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0896 - loss: 3.9262\n",
            "Epoch 4/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1170 - loss: 3.7528\n",
            "Epoch 5/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1339 - loss: 3.6212\n",
            "Epoch 6/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1445 - loss: 3.5493\n",
            "Epoch 7/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1662 - loss: 3.4208\n",
            "Epoch 8/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1905 - loss: 3.3338\n",
            "Epoch 9/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2022 - loss: 3.2543\n",
            "Epoch 10/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2123 - loss: 3.1686\n",
            "Epoch 11/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2211 - loss: 3.1355\n",
            "Epoch 12/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2344 - loss: 3.0789\n",
            "Epoch 13/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2410 - loss: 3.0359\n",
            "Epoch 14/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2550 - loss: 2.9358\n",
            "Epoch 15/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2736 - loss: 2.8722\n",
            "Epoch 16/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2779 - loss: 2.8210\n",
            "Epoch 17/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2833 - loss: 2.7799\n",
            "Epoch 18/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2959 - loss: 2.7241\n",
            "Epoch 19/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3102 - loss: 2.6419\n",
            "Epoch 20/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3143 - loss: 2.6161\n",
            "Epoch 21/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3271 - loss: 2.5692\n",
            "Epoch 22/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3419 - loss: 2.4940\n",
            "Epoch 23/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3471 - loss: 2.4416\n",
            "Epoch 24/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3527 - loss: 2.4171\n",
            "Epoch 25/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3699 - loss: 2.3514\n",
            "Epoch 26/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3720 - loss: 2.2959\n",
            "Epoch 27/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3943 - loss: 2.2433\n",
            "Epoch 28/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4021 - loss: 2.2274\n",
            "Epoch 29/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4143 - loss: 2.1301\n",
            "Epoch 30/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4235 - loss: 2.1453\n",
            "Epoch 31/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4381 - loss: 2.0291\n",
            "Epoch 32/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4465 - loss: 2.0132\n",
            "Epoch 33/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4364 - loss: 2.0113\n",
            "Epoch 34/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4637 - loss: 1.9118\n",
            "Epoch 35/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4861 - loss: 1.8496\n",
            "Epoch 36/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4808 - loss: 1.8228\n",
            "Epoch 37/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4974 - loss: 1.7814\n",
            "Epoch 38/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5031 - loss: 1.7372\n",
            "Epoch 39/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5171 - loss: 1.7105\n",
            "Epoch 40/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5383 - loss: 1.6297\n",
            "Epoch 41/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5436 - loss: 1.6019\n",
            "Epoch 42/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5528 - loss: 1.5570\n",
            "Epoch 43/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5631 - loss: 1.5383\n",
            "Epoch 44/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5716 - loss: 1.4860\n",
            "Epoch 45/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5812 - loss: 1.4642\n",
            "Epoch 46/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5962 - loss: 1.3967\n",
            "Epoch 47/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6032 - loss: 1.3404\n",
            "Epoch 48/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6038 - loss: 1.3562\n",
            "Epoch 49/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6259 - loss: 1.2636\n",
            "Epoch 50/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6339 - loss: 1.2346\n",
            "Epoch 51/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6440 - loss: 1.2008\n",
            "Epoch 52/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6583 - loss: 1.1649\n",
            "Epoch 53/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6699 - loss: 1.1303\n",
            "Epoch 54/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6803 - loss: 1.0824\n",
            "Epoch 55/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6997 - loss: 1.0246\n",
            "Epoch 56/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6802 - loss: 1.0830\n",
            "Epoch 57/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6991 - loss: 1.0159\n",
            "Epoch 58/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7015 - loss: 0.9791\n",
            "Epoch 59/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7340 - loss: 0.9154\n",
            "Epoch 60/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7436 - loss: 0.8772\n",
            "Epoch 61/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7457 - loss: 0.8617\n",
            "Epoch 62/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7578 - loss: 0.8212\n",
            "Epoch 63/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7616 - loss: 0.7998\n",
            "Epoch 64/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7637 - loss: 0.7832\n",
            "Epoch 65/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7744 - loss: 0.7354\n",
            "Epoch 66/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7805 - loss: 0.7209\n",
            "Epoch 67/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7993 - loss: 0.6871\n",
            "Epoch 68/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7957 - loss: 0.6797\n",
            "Epoch 69/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7986 - loss: 0.6489\n",
            "Epoch 70/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8166 - loss: 0.6095\n",
            "Epoch 71/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8239 - loss: 0.5758\n",
            "Epoch 72/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8220 - loss: 0.5707\n",
            "Epoch 73/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8314 - loss: 0.5422\n",
            "Epoch 74/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8238 - loss: 0.5675\n",
            "Epoch 75/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8635 - loss: 0.4721\n",
            "Epoch 76/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8466 - loss: 0.5044\n",
            "Epoch 77/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8370 - loss: 0.5142\n",
            "Epoch 78/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8498 - loss: 0.4800\n",
            "Epoch 79/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8429 - loss: 0.4985\n",
            "Epoch 80/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8597 - loss: 0.4492\n",
            "Epoch 81/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8931 - loss: 0.3716\n",
            "Epoch 82/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8723 - loss: 0.4222\n",
            "Epoch 83/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8719 - loss: 0.4075\n",
            "Epoch 84/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8648 - loss: 0.4241\n",
            "Epoch 85/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8849 - loss: 0.3721\n",
            "Epoch 86/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8894 - loss: 0.3473\n",
            "Epoch 87/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9293 - loss: 0.2532\n",
            "Epoch 88/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9196 - loss: 0.2709\n",
            "Epoch 89/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8795 - loss: 0.3852\n",
            "Epoch 90/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8676 - loss: 0.4171\n",
            "Epoch 91/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8975 - loss: 0.3226\n",
            "Epoch 92/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9200 - loss: 0.2723\n",
            "Epoch 93/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9364 - loss: 0.2205\n",
            "Epoch 94/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9282 - loss: 0.2391\n",
            "Epoch 95/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9236 - loss: 0.2577\n",
            "Epoch 96/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9118 - loss: 0.2872\n",
            "Epoch 97/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8619 - loss: 0.4121\n",
            "Epoch 98/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8873 - loss: 0.3413\n",
            "Epoch 99/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9457 - loss: 0.1847\n",
            "Epoch 100/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9490 - loss: 0.1696\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(<__main__.MiAutoencoder at 0x7ba6999c5910>,\n",
              " <__main__.MiClasificador at 0x7ba754780290>)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semisupervised_training(autoencoder, classifier, train_data, train_label, unlabelled_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dENih7EhH_w1",
      "metadata": {
        "id": "dENih7EhH_w1"
      },
      "source": [
        "Evaluamos el modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AUINq1ZxxB0Q",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUINq1ZxxB0Q",
        "outputId": "ecc6ae5f-f64c-4b32-8964-131c87543686"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "Test accuracy : 0.19290000200271606\n"
          ]
        }
      ],
      "source": [
        "# Evaluamos en test\n",
        "pred_test = autoencoder.get_encoded_data(x_test)\n",
        "print('Test accuracy :', classifier.score(pred_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5z9b2bBixCIr",
      "metadata": {
        "id": "5z9b2bBixCIr"
      },
      "source": [
        "- <u>Cuestiones</u>\n",
        "\n",
        "  1. **¿Cuál es la arquitectura del modelo? ¿Y sus hiperparámetros (epochs, batch size, optimizador, ...)?**\n",
        "\n",
        "    El modelo consta de 2 partes, un autoencoder (encoder + decoder) y un clasificador.\n",
        "    \n",
        "    La arquitectura del encoder es exactamente la misma que la del modelo convolucional del primer ejercicio, a excepción de la última capa de MaxPooling, la capa de aplanamiento y la capa de salida. El decoder consta de 5 capas *Conv2DTranspose* y 2 capas de *UpSampling2D* que nos ayudarán a recuperar la imagen original.\n",
        "\n",
        "    En cuanto al clasificador, se incluye la capa de entrada con las dimensiones de salida del encoder, una capa de *flatten* y 4 capas *Dense*, siendo la última de 100 neuronas (una por cada clase) con función de activación *softmax*.\n",
        "\n",
        "    Los hiperparámetros utilizados son los siguientes:\n",
        "    - *batch\\_size*: 128\n",
        "    - *epochs*: 50 en el autoencoder y 100 en el clasificador\n",
        "    \n",
        "    El optimizador utilizado es *adam* y la función de pérdida *categorical_crossentropy*.\n",
        "\n",
        "  2. **¿Cuál es la precisión del modelo en entrenamiento? ¿Y en test?**\n",
        "\n",
        "    La precisión durante el entrenamiento sube hasta $0.9490$. En el conjunto de test la precisión es de $0,1929$\n",
        "\n",
        "  3. **¿Se mejoran los resultados obtenidos en los puntos anteriores?**\n",
        "\n",
        "    La precisión en el conjunto de test ha bajado respecto al modelo de autoaprendizaje, aunque la precisión en el conjunto de entrenamiento ha aumentado.\n",
        "\n",
        "  4. **¿Qué conclusiones sacas de este apartado?**\n",
        "\n",
        "    El entrenamiento sigue teniendo problemas importantes de generalización. La precisión en el conjunto de test es muy baja, lo que indica que el modelo no está aprendiendo patrones generales de los datos. Esto puede deberse a la complejidad del modelo y a la cantidad limitada de datos etiquetados."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0n2QQabK2FU0",
      "metadata": {
        "id": "0n2QQabK2FU0"
      },
      "source": [
        "### Modelo 4: Autoencoder en un paso"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4w2drF5I2ZED",
      "metadata": {
        "id": "4w2drF5I2ZED"
      },
      "source": [
        "Definimos un autoencoder con exactamente la misma arquitectura que en el apartado anterior.\n",
        "\n",
        "El resultado de combinar el encoder con el clasificador será exactamente igual a la arquitectura definida en el punto 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DteAj7P09lEy",
      "metadata": {
        "id": "DteAj7P09lEy"
      },
      "outputs": [],
      "source": [
        "class MiClasificadorSemisupervisado:\n",
        "    def __init__(self, input_shape):\n",
        "        # Capa de entrada con input_shape aplanada 32*32*3\n",
        "        input_layer = tf.keras.layers.Input(shape=input_shape)\n",
        "\n",
        "        # Encoder\n",
        "        # Recuperamos el tamaño (32, 32, 3)\n",
        "        encoder = tf.keras.layers.Reshape((32, 32, 3))(input_layer)\n",
        "        encoder = tf.keras.layers.Conv2D(16, (3, 3), activation='relu')(encoder)\n",
        "        encoder = tf.keras.layers.Conv2D(32, (3, 3), activation='relu')(encoder)\n",
        "        encoder = tf.keras.layers.MaxPooling2D((2, 2))(encoder)\n",
        "        encoder = tf.keras.layers.Conv2D(64, (3, 3), activation='relu')(encoder)\n",
        "        encoder = tf.keras.layers.MaxPooling2D((2, 2))(encoder)\n",
        "        encoder = tf.keras.layers.Conv2D(128, (3,3), activation='relu')(encoder)\n",
        "\n",
        "        # Decoder\n",
        "        decoder = layers.Conv2DTranspose(128, (3, 3), activation='relu')(encoder)\n",
        "        decoder = layers.UpSampling2D((2, 2))(decoder)\n",
        "        decoder = layers.Conv2DTranspose(64, (3, 3), activation='relu')(decoder)\n",
        "        decoder = layers.UpSampling2D((2, 2))(decoder)\n",
        "        decoder = layers.Conv2DTranspose(32, (3, 3), activation='relu')(decoder)\n",
        "        decoder = layers.Conv2DTranspose(16, (3, 3), activation='relu', padding='same')(decoder)\n",
        "        decoder = layers.Conv2DTranspose(3, (3, 3), activation='sigmoid')(decoder)\n",
        "\n",
        "        decoder = tf.keras.layers.Flatten()(decoder)\n",
        "\n",
        "        # Classifier\n",
        "        classifier = tf.keras.layers.Flatten()(encoder)\n",
        "        # Misma arquitectura que modelo 1, es decir una sola capa densa\n",
        "        classifier = tf.keras.layers.Dense(100, activation='softmax')(classifier)\n",
        "\n",
        "        # Creación del modelo\n",
        "        self.model = tf.keras.models.Model(inputs=input_layer, outputs=[decoder, classifier])\n",
        "\n",
        "        # Compilar\n",
        "        self.model.compile(optimizer='adam', loss=['mse', 'sparse_categorical_crossentropy'], metrics=['accuracy', 'accuracy'])\n",
        "\n",
        "    def fit(self, X, y, unlabeled_data):\n",
        "        # Combinamos labeled y unlabeled data (con etiqueta 0)\n",
        "        x_train_combined = np.concatenate([X, unlabeled_data], axis=0)\n",
        "        y_train_combined = np.concatenate((y, np.full(len(unlabeled_data), 0)), axis=0)\n",
        "\n",
        "        # Hacemos un aplanado\n",
        "        x_train_combined = x_train_combined.reshape(x_train_combined.shape[0], -1)\n",
        "\n",
        "        # Sample weights\n",
        "        # Para el autoencoder todo 1 y para el clasificador sin tener en cuenta los no etiquetados\n",
        "        sample_weight = [np.ones(len(x_train_combined)), np.concatenate((np.ones(len(y)), np.zeros(len(unlabeled_data))))]\n",
        "\n",
        "        self.model.fit(\n",
        "            x_train_combined,\n",
        "            [x_train_combined, y_train_combined],\n",
        "            batch_size=128,\n",
        "            epochs=100,\n",
        "            sample_weight = sample_weight,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.argmax(self.model.predict(X), axis=1)\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        return self.model.predict(X)\n",
        "\n",
        "    def score(self, X, y):\n",
        "        score = self.model.evaluate(X, [X, y])\n",
        "        return score\n",
        "\n",
        "    def __del__(self):\n",
        "        tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RJli_WAN_k2E",
      "metadata": {
        "id": "RJli_WAN_k2E"
      },
      "source": [
        "Redefinimos la función de semisupervised_training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ev26v8QZ_kFD",
      "metadata": {
        "id": "ev26v8QZ_kFD"
      },
      "outputs": [],
      "source": [
        "def semisupervised_training_v2(model, x_train, y_train, unlabeled_data):\n",
        "    model.fit(x_train, y_train, unlabeled_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "W5PRO003_stm",
      "metadata": {
        "id": "W5PRO003_stm"
      },
      "source": [
        "Entrenamos el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "803c4934",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 25ms/step - dense_accuracy: 0.0081 - dense_loss: 0.8893 - flatten_accuracy: 0.0025 - flatten_loss: 0.0420 - loss: 0.9313\n",
            "Epoch 2/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - dense_accuracy: 0.0410 - dense_loss: 0.7373 - flatten_accuracy: 0.0029 - flatten_loss: 0.0241 - loss: 0.7614\n",
            "Epoch 3/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - dense_accuracy: 0.0531 - dense_loss: 0.6527 - flatten_accuracy: 0.0039 - flatten_loss: 0.0203 - loss: 0.6730\n",
            "Epoch 4/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - dense_accuracy: 0.0692 - dense_loss: 0.5634 - flatten_accuracy: 0.0044 - flatten_loss: 0.0186 - loss: 0.5820\n",
            "Epoch 5/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - dense_accuracy: 0.0843 - dense_loss: 0.4855 - flatten_accuracy: 0.0050 - flatten_loss: 0.0185 - loss: 0.5040\n",
            "Epoch 6/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.1023 - dense_loss: 0.4141 - flatten_accuracy: 0.0058 - flatten_loss: 0.0183 - loss: 0.4324\n",
            "Epoch 7/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.1173 - dense_loss: 0.3465 - flatten_accuracy: 0.0070 - flatten_loss: 0.0177 - loss: 0.3642\n",
            "Epoch 8/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.1345 - dense_loss: 0.2740 - flatten_accuracy: 0.0071 - flatten_loss: 0.0172 - loss: 0.2912\n",
            "Epoch 9/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - dense_accuracy: 0.1520 - dense_loss: 0.1944 - flatten_accuracy: 0.0065 - flatten_loss: 0.0173 - loss: 0.2118\n",
            "Epoch 10/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.1663 - dense_loss: 0.1471 - flatten_accuracy: 0.0074 - flatten_loss: 0.0170 - loss: 0.1641\n",
            "Epoch 11/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.1795 - dense_loss: 0.1031 - flatten_accuracy: 0.0088 - flatten_loss: 0.0164 - loss: 0.1195\n",
            "Epoch 12/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.1856 - dense_loss: 0.0787 - flatten_accuracy: 0.0080 - flatten_loss: 0.0165 - loss: 0.0952\n",
            "Epoch 13/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - dense_accuracy: 0.1901 - dense_loss: 0.0592 - flatten_accuracy: 0.0073 - flatten_loss: 0.0162 - loss: 0.0754\n",
            "Epoch 14/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.1918 - dense_loss: 0.0463 - flatten_accuracy: 0.0075 - flatten_loss: 0.0161 - loss: 0.0624\n",
            "Epoch 15/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - dense_accuracy: 0.1970 - dense_loss: 0.0416 - flatten_accuracy: 0.0071 - flatten_loss: 0.0162 - loss: 0.0578\n",
            "Epoch 16/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2013 - dense_loss: 0.0333 - flatten_accuracy: 0.0083 - flatten_loss: 0.0159 - loss: 0.0492\n",
            "Epoch 17/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.1969 - dense_loss: 0.0385 - flatten_accuracy: 0.0082 - flatten_loss: 0.0160 - loss: 0.0544\n",
            "Epoch 18/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2007 - dense_loss: 0.0319 - flatten_accuracy: 0.0069 - flatten_loss: 0.0159 - loss: 0.0478\n",
            "Epoch 19/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.1959 - dense_loss: 0.0314 - flatten_accuracy: 0.0073 - flatten_loss: 0.0158 - loss: 0.0472\n",
            "Epoch 20/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2022 - dense_loss: 0.0267 - flatten_accuracy: 0.0082 - flatten_loss: 0.0156 - loss: 0.0423\n",
            "Epoch 21/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2050 - dense_loss: 0.0229 - flatten_accuracy: 0.0080 - flatten_loss: 0.0157 - loss: 0.0386\n",
            "Epoch 22/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2017 - dense_loss: 0.0226 - flatten_accuracy: 0.0083 - flatten_loss: 0.0156 - loss: 0.0382\n",
            "Epoch 23/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - dense_accuracy: 0.2008 - dense_loss: 0.0220 - flatten_accuracy: 0.0094 - flatten_loss: 0.0154 - loss: 0.0374\n",
            "Epoch 24/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - dense_accuracy: 0.2063 - dense_loss: 0.0190 - flatten_accuracy: 0.0084 - flatten_loss: 0.0152 - loss: 0.0343\n",
            "Epoch 25/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2002 - dense_loss: 0.0226 - flatten_accuracy: 0.0081 - flatten_loss: 0.0153 - loss: 0.0378\n",
            "Epoch 26/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2018 - dense_loss: 0.0257 - flatten_accuracy: 0.0090 - flatten_loss: 0.0153 - loss: 0.0411\n",
            "Epoch 27/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2045 - dense_loss: 0.0199 - flatten_accuracy: 0.0078 - flatten_loss: 0.0153 - loss: 0.0352\n",
            "Epoch 28/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2033 - dense_loss: 0.0187 - flatten_accuracy: 0.0078 - flatten_loss: 0.0153 - loss: 0.0340\n",
            "Epoch 29/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - dense_accuracy: 0.2037 - dense_loss: 0.0201 - flatten_accuracy: 0.0077 - flatten_loss: 0.0153 - loss: 0.0354\n",
            "Epoch 30/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2012 - dense_loss: 0.0194 - flatten_accuracy: 0.0075 - flatten_loss: 0.0154 - loss: 0.0348\n",
            "Epoch 31/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - dense_accuracy: 0.2051 - dense_loss: 0.0149 - flatten_accuracy: 0.0089 - flatten_loss: 0.0151 - loss: 0.0300\n",
            "Epoch 32/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - dense_accuracy: 0.2053 - dense_loss: 0.0176 - flatten_accuracy: 0.0083 - flatten_loss: 0.0152 - loss: 0.0328\n",
            "Epoch 33/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2049 - dense_loss: 0.0189 - flatten_accuracy: 0.0082 - flatten_loss: 0.0151 - loss: 0.0341\n",
            "Epoch 34/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2044 - dense_loss: 0.0202 - flatten_accuracy: 0.0079 - flatten_loss: 0.0152 - loss: 0.0354\n",
            "Epoch 35/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - dense_accuracy: 0.2042 - dense_loss: 0.0188 - flatten_accuracy: 0.0077 - flatten_loss: 0.0150 - loss: 0.0339\n",
            "Epoch 36/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - dense_accuracy: 0.2081 - dense_loss: 0.0127 - flatten_accuracy: 0.0087 - flatten_loss: 0.0149 - loss: 0.0276\n",
            "Epoch 37/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2061 - dense_loss: 0.0141 - flatten_accuracy: 0.0077 - flatten_loss: 0.0147 - loss: 0.0288\n",
            "Epoch 38/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2066 - dense_loss: 0.0186 - flatten_accuracy: 0.0094 - flatten_loss: 0.0153 - loss: 0.0338\n",
            "Epoch 39/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2034 - dense_loss: 0.0118 - flatten_accuracy: 0.0089 - flatten_loss: 0.0150 - loss: 0.0268\n",
            "Epoch 40/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2048 - dense_loss: 0.0249 - flatten_accuracy: 0.0089 - flatten_loss: 0.0153 - loss: 0.0402\n",
            "Epoch 41/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2045 - dense_loss: 0.0159 - flatten_accuracy: 0.0084 - flatten_loss: 0.0150 - loss: 0.0309\n",
            "Epoch 42/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2066 - dense_loss: 0.0124 - flatten_accuracy: 0.0084 - flatten_loss: 0.0148 - loss: 0.0272\n",
            "Epoch 43/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2060 - dense_loss: 0.0147 - flatten_accuracy: 0.0084 - flatten_loss: 0.0152 - loss: 0.0298\n",
            "Epoch 44/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2067 - dense_loss: 0.0153 - flatten_accuracy: 0.0087 - flatten_loss: 0.0150 - loss: 0.0303\n",
            "Epoch 45/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2059 - dense_loss: 0.0151 - flatten_accuracy: 0.0088 - flatten_loss: 0.0149 - loss: 0.0300\n",
            "Epoch 46/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2046 - dense_loss: 0.0105 - flatten_accuracy: 0.0081 - flatten_loss: 0.0148 - loss: 0.0253\n",
            "Epoch 47/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2101 - dense_loss: 0.0112 - flatten_accuracy: 0.0086 - flatten_loss: 0.0148 - loss: 0.0261\n",
            "Epoch 48/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2015 - dense_loss: 0.0211 - flatten_accuracy: 0.0084 - flatten_loss: 0.0152 - loss: 0.0363\n",
            "Epoch 49/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - dense_accuracy: 0.2044 - dense_loss: 0.0119 - flatten_accuracy: 0.0080 - flatten_loss: 0.0150 - loss: 0.0269\n",
            "Epoch 50/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - dense_accuracy: 0.2053 - dense_loss: 0.0098 - flatten_accuracy: 0.0095 - flatten_loss: 0.0149 - loss: 0.0247\n",
            "Epoch 51/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2046 - dense_loss: 0.0205 - flatten_accuracy: 0.0098 - flatten_loss: 0.0150 - loss: 0.0355\n",
            "Epoch 52/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2034 - dense_loss: 0.0146 - flatten_accuracy: 0.0086 - flatten_loss: 0.0148 - loss: 0.0294\n",
            "Epoch 53/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - dense_accuracy: 0.2098 - dense_loss: 0.0090 - flatten_accuracy: 0.0095 - flatten_loss: 0.0145 - loss: 0.0235\n",
            "Epoch 54/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2073 - dense_loss: 0.0108 - flatten_accuracy: 0.0090 - flatten_loss: 0.0147 - loss: 0.0255\n",
            "Epoch 55/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2088 - dense_loss: 0.0119 - flatten_accuracy: 0.0104 - flatten_loss: 0.0147 - loss: 0.0266\n",
            "Epoch 56/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2060 - dense_loss: 0.0140 - flatten_accuracy: 0.0098 - flatten_loss: 0.0148 - loss: 0.0287\n",
            "Epoch 57/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - dense_accuracy: 0.2033 - dense_loss: 0.0155 - flatten_accuracy: 0.0099 - flatten_loss: 0.0149 - loss: 0.0304\n",
            "Epoch 58/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2013 - dense_loss: 0.0177 - flatten_accuracy: 0.0090 - flatten_loss: 0.0149 - loss: 0.0325\n",
            "Epoch 59/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2071 - dense_loss: 0.0081 - flatten_accuracy: 0.0099 - flatten_loss: 0.0145 - loss: 0.0225\n",
            "Epoch 60/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - dense_accuracy: 0.2050 - dense_loss: 0.0098 - flatten_accuracy: 0.0097 - flatten_loss: 0.0147 - loss: 0.0245\n",
            "Epoch 61/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2034 - dense_loss: 0.0097 - flatten_accuracy: 0.0099 - flatten_loss: 0.0147 - loss: 0.0244\n",
            "Epoch 62/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2090 - dense_loss: 0.0090 - flatten_accuracy: 0.0094 - flatten_loss: 0.0145 - loss: 0.0235\n",
            "Epoch 63/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2074 - dense_loss: 0.0165 - flatten_accuracy: 0.0085 - flatten_loss: 0.0148 - loss: 0.0313\n",
            "Epoch 64/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2053 - dense_loss: 0.0155 - flatten_accuracy: 0.0085 - flatten_loss: 0.0147 - loss: 0.0302\n",
            "Epoch 65/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2081 - dense_loss: 0.0109 - flatten_accuracy: 0.0101 - flatten_loss: 0.0147 - loss: 0.0257\n",
            "Epoch 66/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2062 - dense_loss: 0.0077 - flatten_accuracy: 0.0094 - flatten_loss: 0.0145 - loss: 0.0222\n",
            "Epoch 67/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2046 - dense_loss: 0.0129 - flatten_accuracy: 0.0088 - flatten_loss: 0.0147 - loss: 0.0276\n",
            "Epoch 68/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2032 - dense_loss: 0.0171 - flatten_accuracy: 0.0097 - flatten_loss: 0.0149 - loss: 0.0320\n",
            "Epoch 69/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2116 - dense_loss: 0.0133 - flatten_accuracy: 0.0095 - flatten_loss: 0.0148 - loss: 0.0280\n",
            "Epoch 70/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2101 - dense_loss: 0.0048 - flatten_accuracy: 0.0092 - flatten_loss: 0.0144 - loss: 0.0192\n",
            "Epoch 71/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - dense_accuracy: 0.2089 - dense_loss: 0.0098 - flatten_accuracy: 0.0110 - flatten_loss: 0.0144 - loss: 0.0243\n",
            "Epoch 72/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2065 - dense_loss: 0.0143 - flatten_accuracy: 0.0091 - flatten_loss: 0.0147 - loss: 0.0290\n",
            "Epoch 73/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2056 - dense_loss: 0.0204 - flatten_accuracy: 0.0100 - flatten_loss: 0.0149 - loss: 0.0353\n",
            "Epoch 74/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2126 - dense_loss: 0.0067 - flatten_accuracy: 0.0091 - flatten_loss: 0.0145 - loss: 0.0212\n",
            "Epoch 75/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2124 - dense_loss: 0.0030 - flatten_accuracy: 0.0094 - flatten_loss: 0.0141 - loss: 0.0171\n",
            "Epoch 76/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - dense_accuracy: 0.2048 - dense_loss: 0.0182 - flatten_accuracy: 0.0089 - flatten_loss: 0.0150 - loss: 0.0333\n",
            "Epoch 77/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2073 - dense_loss: 0.0107 - flatten_accuracy: 0.0093 - flatten_loss: 0.0146 - loss: 0.0253\n",
            "Epoch 78/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2108 - dense_loss: 0.0092 - flatten_accuracy: 0.0091 - flatten_loss: 0.0147 - loss: 0.0238\n",
            "Epoch 79/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - dense_accuracy: 0.2079 - dense_loss: 0.0080 - flatten_accuracy: 0.0096 - flatten_loss: 0.0145 - loss: 0.0226\n",
            "Epoch 80/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2035 - dense_loss: 0.0089 - flatten_accuracy: 0.0092 - flatten_loss: 0.0146 - loss: 0.0235\n",
            "Epoch 81/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2098 - dense_loss: 0.0068 - flatten_accuracy: 0.0094 - flatten_loss: 0.0145 - loss: 0.0213\n",
            "Epoch 82/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2037 - dense_loss: 0.0103 - flatten_accuracy: 0.0095 - flatten_loss: 0.0146 - loss: 0.0249\n",
            "Epoch 83/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2080 - dense_loss: 0.0094 - flatten_accuracy: 0.0088 - flatten_loss: 0.0145 - loss: 0.0239\n",
            "Epoch 84/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2068 - dense_loss: 0.0078 - flatten_accuracy: 0.0099 - flatten_loss: 0.0145 - loss: 0.0223\n",
            "Epoch 85/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - dense_accuracy: 0.2078 - dense_loss: 0.0074 - flatten_accuracy: 0.0102 - flatten_loss: 0.0144 - loss: 0.0218\n",
            "Epoch 86/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2056 - dense_loss: 0.0121 - flatten_accuracy: 0.0091 - flatten_loss: 0.0146 - loss: 0.0267\n",
            "Epoch 87/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2042 - dense_loss: 0.0105 - flatten_accuracy: 0.0095 - flatten_loss: 0.0146 - loss: 0.0251\n",
            "Epoch 88/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2076 - dense_loss: 0.0090 - flatten_accuracy: 0.0092 - flatten_loss: 0.0145 - loss: 0.0235\n",
            "Epoch 89/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - dense_accuracy: 0.2090 - dense_loss: 0.0121 - flatten_accuracy: 0.0092 - flatten_loss: 0.0146 - loss: 0.0267\n",
            "Epoch 90/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - dense_accuracy: 0.2061 - dense_loss: 0.0112 - flatten_accuracy: 0.0097 - flatten_loss: 0.0144 - loss: 0.0256\n",
            "Epoch 91/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2100 - dense_loss: 0.0094 - flatten_accuracy: 0.0092 - flatten_loss: 0.0144 - loss: 0.0238\n",
            "Epoch 92/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - dense_accuracy: 0.2053 - dense_loss: 0.0146 - flatten_accuracy: 0.0091 - flatten_loss: 0.0145 - loss: 0.0291\n",
            "Epoch 93/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - dense_accuracy: 0.2107 - dense_loss: 0.0074 - flatten_accuracy: 0.0089 - flatten_loss: 0.0144 - loss: 0.0218\n",
            "Epoch 94/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - dense_accuracy: 0.2096 - dense_loss: 0.0121 - flatten_accuracy: 0.0094 - flatten_loss: 0.0146 - loss: 0.0267\n",
            "Epoch 95/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2064 - dense_loss: 0.0090 - flatten_accuracy: 0.0093 - flatten_loss: 0.0144 - loss: 0.0234\n",
            "Epoch 96/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2099 - dense_loss: 0.0090 - flatten_accuracy: 0.0093 - flatten_loss: 0.0145 - loss: 0.0234\n",
            "Epoch 97/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - dense_accuracy: 0.2054 - dense_loss: 0.0091 - flatten_accuracy: 0.0096 - flatten_loss: 0.0146 - loss: 0.0237\n",
            "Epoch 98/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2072 - dense_loss: 0.0082 - flatten_accuracy: 0.0086 - flatten_loss: 0.0144 - loss: 0.0226\n",
            "Epoch 99/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2054 - dense_loss: 0.0108 - flatten_accuracy: 0.0093 - flatten_loss: 0.0145 - loss: 0.0253\n",
            "Epoch 100/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2103 - dense_loss: 0.0151 - flatten_accuracy: 0.0093 - flatten_loss: 0.0147 - loss: 0.0298\n"
          ]
        }
      ],
      "source": [
        "# Creamos el clasificador\n",
        "model = MiClasificadorSemisupervisado(input_shape=(32*32*3, ))\n",
        "semisupervised_training_v2(model, train_data, train_label, unlabelled_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GDTYO5IHFezm",
      "metadata": {
        "id": "GDTYO5IHFezm"
      },
      "source": [
        "Evaluamos en el conjunto de test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6da90119",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - dense_accuracy: 0.2062 - dense_loss: 19.9344 - flatten_accuracy: 0.0082 - flatten_loss: 0.0159 - loss: 19.9502\n",
            "Test accuracy : 0.2029999941587448\n"
          ]
        }
      ],
      "source": [
        "x_test = x_test.reshape(x_test.shape[0], (32*32*3))\n",
        "print('Test accuracy :', model.score(x_test, y_test)[3])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d96fabf",
      "metadata": {},
      "source": [
        "<u>Cuestiones</u>\n",
        "1. ¿Cuál es la arquitectura del modelo? ¿Y sus hiperparámetros (epochs, batch size, optimizador, ...)?\n",
        "\n",
        "  En este caso, tenemos un solo modelo con dos salidas diferentes que se entrenaran de forma paralela (autoencoder y encoder+clasificador)\n",
        "\n",
        "  La arquitectura del autoencoder y del clasificador son las mismas que anteriormente.\n",
        "\n",
        "  A la hora de compliar el modelo es importante destacar que utilizaremos diferentes funciones de pérdida para las salidas, *mse* y *sparse_categorical_crossentropy*.\n",
        "\n",
        "  Los hiperparámetros son:\n",
        "  - *batch\\_size*: 128\n",
        "  - *epochs*: 100\n",
        "\n",
        "\n",
        "2. ¿Cuál es la precisión del modelo en entrenamiento? ¿Y en test?\n",
        "\n",
        "  En entrenamiento se alcanza una precisión de $0.2103$ y en el conjunto de test de $0.2029$.\n",
        "\n",
        "3. ¿Se mejoran los resultados obtenidos en los puntos anteriores?\n",
        "\n",
        "  Obtenemos el peor resultado hasta ahora en el entrenamiento pero el rendimiento en el conjunto de test sigue siendo similar.\n",
        "\n",
        "4. ¿Qué conclusiones sacas de este apartado?\n",
        "\n",
        "  El utilizar datos no etiquetados puede estar provocando que en el entrenamiento del autoencoder no se obtenga una buena representación en espacio reducido."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "G5dgl8x9ei42",
      "metadata": {
        "id": "G5dgl8x9ei42"
      },
      "source": [
        "### Entrenamiento de los modelos eliminando datos atípicos"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6X9T61Zpe2bC",
      "metadata": {
        "id": "6X9T61Zpe2bC"
      },
      "source": [
        "Reutilizamos código del lab9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "TPVIP8UFe3rH",
      "metadata": {
        "id": "TPVIP8UFe3rH"
      },
      "outputs": [],
      "source": [
        "class ChangeRCallback(tf.keras.callbacks.Callback):\n",
        "   def __init__(self, train_data, delta=.025, steps=3):\n",
        "       super().__init__()\n",
        "       self.train_data = train_data\n",
        "       self.delta = delta\n",
        "       self.steps = steps\n",
        "       self.cont = 0\n",
        "\n",
        "   def on_epoch_end(self, epoch, logs=None):\n",
        "       sorted_values = np.sort(self.model.predict(self.train_data).flatten())\n",
        "       new_value = sorted_values[int(len(sorted_values) * (1. - self.model.nu))]\n",
        "       old_value = self.model.r.numpy()\n",
        "       print('Cambiando r a', new_value, ', max:', sorted_values.max(), ', min:', sorted_values.min())\n",
        "       self.model.r.assign(new_value)\n",
        "       if np.abs(old_value - new_value) < self.delta:\n",
        "            self.cont += 1\n",
        "            if self.cont >= self.steps:\n",
        "                print('Convergencia obtenida. Finalizando el entrenamiento.')\n",
        "                self.model.stop_training = True\n",
        "       else:\n",
        "            self.cont = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "ndlZzsJ_fEcM",
      "metadata": {
        "id": "ndlZzsJ_fEcM"
      },
      "outputs": [],
      "source": [
        "class DetectorAnomalias:\n",
        "\n",
        "    def __init__(self, input_shape, nu=.5):\n",
        "        # Todas las capas deben incluir regularización L2\n",
        "        self.model = tf.keras.Sequential()\n",
        "        self.model.add(tf.keras.layers.InputLayer(shape=input_shape))\n",
        "        self.model.add(tf.keras.layers.Conv2D(16, (3,3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
        "        self.model.add(tf.keras.layers.Conv2D(32, (3,3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
        "        self.model.add(tf.keras.layers.MaxPooling2D((2,2)))\n",
        "        self.model.add(tf.keras.layers.Conv2D(64, (3,3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
        "        self.model.add(tf.keras.layers.MaxPooling2D((2,2)))\n",
        "        self.model.add(tf.keras.layers.Conv2D(128, (3,3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
        "        self.model.add(tf.keras.layers.MaxPooling2D((2,2)))\n",
        "        self.model.add(tf.keras.layers.Flatten())\n",
        "        self.model.add(tf.keras.layers.Dense(1, activation='sigmoid', kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
        "\n",
        "        self.model.r = tf.Variable(1.0, trainable=False, name='r', dtype=tf.float32)\n",
        "        self.model.nu = tf.Variable(nu, trainable=False, name='nu', dtype=tf.float32)\n",
        "\n",
        "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "        self.model.compile(optimizer=self.optimizer, loss=self.loss_function, metrics=['accuracy'])\n",
        "\n",
        "    def loss_function(self, y_true, y_pred):\n",
        "        loss = (1/self.model.nu) * tf.reduce_mean(tf.maximum(0., self.model.r - y_pred))\n",
        "        return loss\n",
        "\n",
        "    def fit(self, X, y=None, sample_weight=None):\n",
        "        dummy_y = np.zeros((len(X), 1)) # Necesario pasar como salida para que keras no de un error\n",
        "        self.model.fit(X, dummy_y, batch_size=128, epochs=100, verbose=1, callbacks=[ChangeRCallback(X, delta=0.025, steps=3)])\n",
        "\n",
        "    def predict(self, X):\n",
        "        pred = self.model.predict(X, batch_size=128, verbose=1)\n",
        "        pred = np.where(pred > self.model.r, 1, 0)\n",
        "        return pred\n",
        "\n",
        "    def __del__(self):\n",
        "        tf.keras.backend.clear_session() # Necesario para liberar la memoria en GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8U7WWjE859a7",
      "metadata": {
        "id": "8U7WWjE859a7"
      },
      "source": [
        "Creamos el modelo y lo entrenamos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "3p0_72ty58Qt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3p0_72ty58Qt",
        "outputId": "dd036cae-be7d-4418-8247-ba46df29c0f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Cambiando r a 0.99590814 , max: 0.99999416 , min: 0.87893873\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 45ms/step - accuracy: 0.0621 - loss: 1.0552\n",
            "Epoch 2/100\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Cambiando r a 0.99488777 , max: 0.99998486 , min: 0.8978026\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.0000e+00 - loss: 0.1003\n",
            "Epoch 3/100\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Cambiando r a 0.99517775 , max: 0.9999579 , min: 0.94331086\n",
            "Convergencia obtenida. Finalizando el entrenamiento.\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 0.0412\n"
          ]
        }
      ],
      "source": [
        "detector = DetectorAnomalias(input_shape=INPUT_SHAPE, nu=0.9)\n",
        "detector.fit(train_data, y=None, sample_weight=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "QQAuBDi560Yk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQAuBDi560Yk",
        "outputId": "bc0b153a-8957-414b-91f2-26de69aea8fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
            "Se han detectado como atipicos el: 10.36573146292585% de los datos sin etiquetar\n"
          ]
        }
      ],
      "source": [
        "atipicos = detector.predict(unlabelled_data)\n",
        "idx = atipicos==1\n",
        "print(f'Se han detectado como atipicos el: {100 - np.mean(atipicos.flatten())*100}% de los datos sin etiquetar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "h2rwG_-1TmQ4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2rwG_-1TmQ4",
        "outputId": "b64cee2a-cab8-4800-edd5-c3209e4a6f9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tamaño de unlabeled_data 39920\n",
            "Tamaño de unlabeled_data_sin_atipicos: 35782 (Eliminados 4138 )\n"
          ]
        }
      ],
      "source": [
        "unlabelled_data_sin_atipicos = unlabelled_data[idx.flatten(),:,:,:]\n",
        "\n",
        "print('Tamaño de unlabeled_data', unlabelled_data.shape[0])\n",
        "print('Tamaño de unlabeled_data_sin_atipicos:', unlabelled_data_sin_atipicos.shape[0], '(Eliminados', unlabelled_data.shape[0] - unlabelled_data_sin_atipicos.shape[0], ')')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FlwWWK4NAQZG",
      "metadata": {
        "id": "FlwWWK4NAQZG"
      },
      "source": [
        "1. Modelo 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZgaLwc4QASA-",
      "metadata": {
        "id": "ZgaLwc4QASA-"
      },
      "outputs": [],
      "source": [
        "# Es exactamente lo mismo. No entrenamos de nuevo porque en este modelo no se utilizan los datos no etiquetados."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kG1lbjgCASXb",
      "metadata": {
        "id": "kG1lbjgCASXb"
      },
      "source": [
        "2. Modelo 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LHDwuZSJATn4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LHDwuZSJATn4",
        "outputId": "46264ad4-38ab-4e01-a203-5f628ebbc9f3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_36\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_36\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">51,300</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │           \u001b[38;5;34m448\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m4,640\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_12 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_13 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_14 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_4 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m51,300\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">148,740</span> (581.02 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m148,740\u001b[0m (581.02 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">148,740</span> (581.02 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m148,740\u001b[0m (581.02 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.0180 - loss: 4.5552\n",
            "Epoch 2/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0773 - loss: 4.1110\n",
            "Epoch 3/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1224 - loss: 3.8096\n",
            "Epoch 4/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.1602 - loss: 3.5538\n",
            "Epoch 5/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.1997 - loss: 3.3604\n",
            "Epoch 6/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2437 - loss: 3.1467\n",
            "Epoch 7/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2699 - loss: 2.9734\n",
            "Epoch 8/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3010 - loss: 2.8203\n",
            "Epoch 9/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3260 - loss: 2.7119\n",
            "Epoch 10/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3490 - loss: 2.5886\n",
            "Epoch 11/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3731 - loss: 2.4763\n",
            "Epoch 12/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4086 - loss: 2.3122\n",
            "Epoch 13/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4439 - loss: 2.1884\n",
            "Epoch 14/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4619 - loss: 2.0700\n",
            "Epoch 15/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4879 - loss: 1.9472\n",
            "Epoch 16/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5189 - loss: 1.8233\n",
            "Epoch 17/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5442 - loss: 1.7108\n",
            "Epoch 18/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5702 - loss: 1.6244\n",
            "Epoch 19/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5949 - loss: 1.4965\n",
            "Epoch 20/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6073 - loss: 1.4230\n",
            "Epoch 21/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6456 - loss: 1.2899\n",
            "Epoch 22/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6577 - loss: 1.2171\n",
            "Epoch 23/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6989 - loss: 1.0895\n",
            "Epoch 24/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7095 - loss: 1.0356\n",
            "Epoch 25/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7372 - loss: 0.9413\n",
            "Epoch 26/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7494 - loss: 0.8879\n",
            "Epoch 27/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7766 - loss: 0.7912\n",
            "Epoch 28/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7984 - loss: 0.7166\n",
            "Epoch 29/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8022 - loss: 0.6812\n",
            "Epoch 30/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8323 - loss: 0.5865\n",
            "Epoch 31/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8491 - loss: 0.5289\n",
            "Epoch 32/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8687 - loss: 0.4617\n",
            "Epoch 33/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8518 - loss: 0.4935\n",
            "Epoch 34/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8780 - loss: 0.4219\n",
            "Epoch 35/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9038 - loss: 0.3442\n",
            "Epoch 36/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9103 - loss: 0.3074\n",
            "Epoch 37/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9314 - loss: 0.2600\n",
            "Epoch 38/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9203 - loss: 0.2678\n",
            "Epoch 39/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9288 - loss: 0.2504\n",
            "Epoch 40/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9235 - loss: 0.2523\n",
            "Epoch 41/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9355 - loss: 0.2267\n",
            "Epoch 42/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9360 - loss: 0.2165\n",
            "Epoch 43/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9304 - loss: 0.2250\n",
            "Epoch 44/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9520 - loss: 0.1667\n",
            "Epoch 45/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9577 - loss: 0.1457\n",
            "Epoch 46/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9662 - loss: 0.1230\n",
            "Epoch 47/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9683 - loss: 0.1215\n",
            "Epoch 48/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9613 - loss: 0.1336\n",
            "Epoch 49/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9486 - loss: 0.1657\n",
            "Epoch 50/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9201 - loss: 0.2417\n",
            "Epoch 51/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9233 - loss: 0.2237\n",
            "Epoch 52/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9449 - loss: 0.1670\n",
            "Epoch 53/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9500 - loss: 0.1620\n",
            "Epoch 54/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9746 - loss: 0.0949\n",
            "Epoch 55/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9886 - loss: 0.0500\n",
            "Epoch 56/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9973 - loss: 0.0233\n",
            "Epoch 57/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9966 - loss: 0.0238\n",
            "Epoch 58/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9958 - loss: 0.0246\n",
            "Epoch 59/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9989 - loss: 0.0137\n",
            "Epoch 60/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9992 - loss: 0.0129\n",
            "Epoch 61/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9992 - loss: 0.0065\n",
            "Epoch 62/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9956 - loss: 0.0214\n",
            "Epoch 63/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9517 - loss: 0.1616\n",
            "Epoch 64/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8495 - loss: 0.5036\n",
            "Epoch 65/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9006 - loss: 0.3134\n",
            "Epoch 66/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9553 - loss: 0.1301\n",
            "Epoch 67/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9804 - loss: 0.0696\n",
            "Epoch 68/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9881 - loss: 0.0444\n",
            "Epoch 69/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9952 - loss: 0.0274\n",
            "Epoch 70/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9991 - loss: 0.0137\n",
            "Epoch 71/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9998 - loss: 0.0059\n",
            "Epoch 72/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0043\n",
            "Epoch 73/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 0.0070\n",
            "Epoch 74/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 0.0060\n",
            "Epoch 75/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0041\n",
            "Epoch 76/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 0.0048\n",
            "Epoch 77/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0024\n",
            "Epoch 78/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0036\n",
            "Epoch 79/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9996 - loss: 0.0133\n",
            "Epoch 80/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9997 - loss: 0.0071\n",
            "Epoch 81/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0020\n",
            "Epoch 82/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 0.0165\n",
            "Epoch 83/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8186 - loss: 0.6642\n",
            "Epoch 84/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8525 - loss: 0.4711\n",
            "Epoch 85/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9421 - loss: 0.1890\n",
            "Epoch 86/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9855 - loss: 0.0539\n",
            "Epoch 87/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9955 - loss: 0.0297\n",
            "Epoch 88/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9994 - loss: 0.0130\n",
            "Epoch 89/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0064\n",
            "Epoch 90/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 0.0053\n",
            "Epoch 91/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0039\n",
            "Epoch 92/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9995 - loss: 0.0130\n",
            "Epoch 93/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9994 - loss: 0.0129\n",
            "Epoch 94/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0023\n",
            "Epoch 95/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 0.0045\n",
            "Epoch 96/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0026\n",
            "Epoch 97/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 0.0033\n",
            "Epoch 98/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0018\n",
            "Epoch 99/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9998 - loss: 0.0045\n",
            "Epoch 100/100\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 0.0021\n",
            "\u001b[1m1119/1119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function DetectorAnomalias.__del__ at 0x7e38f68bb240>\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-21-0e7cffeea22a>\", line 39, in __del__\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/common/global_state.py\", line 82, in clear_session\n",
            "    tf.compat.v1.reset_default_graph()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\", line 5111, in reset_default_graph\n",
            "    raise AssertionError(\"Do not use tf.reset_default_graph() to clear \"\n",
            "AssertionError: Do not use tf.reset_default_graph() to clear nested graphs. If you need a cleared graph, exit the nesting and create a new graph.\n",
            "Exception ignored in: <function DetectorAnomalias.__del__ at 0x7e3908cda5c0>\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-24-0e7cffeea22a>\", line 39, in __del__\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/common/global_state.py\", line 82, in clear_session\n",
            "    tf.compat.v1.reset_default_graph()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\", line 5111, in reset_default_graph\n",
            "    raise AssertionError(\"Do not use tf.reset_default_graph() to clear \"\n",
            "AssertionError: Do not use tf.reset_default_graph() to clear nested graphs. If you need a cleared graph, exit the nesting and create a new graph.\n",
            "Exception ignored in: <function DetectorAnomalias.__del__ at 0x7e38025287c0>\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-32-0e7cffeea22a>\", line 39, in __del__\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/common/global_state.py\", line 82, in clear_session\n",
            "    tf.compat.v1.reset_default_graph()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\", line 5111, in reset_default_graph\n",
            "    raise AssertionError(\"Do not use tf.reset_default_graph() to clear \"\n",
            "AssertionError: Do not use tf.reset_default_graph() to clear nested graphs. If you need a cleared graph, exit the nesting and create a new graph.\n",
            "Exception ignored in: <function DetectorAnomalias.__del__ at 0x7e37f0607c40>\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-36-0e7cffeea22a>\", line 39, in __del__\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/common/global_state.py\", line 82, in clear_session\n",
            "    tf.compat.v1.reset_default_graph()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\", line 5111, in reset_default_graph\n",
            "    raise AssertionError(\"Do not use tf.reset_default_graph() to clear \"\n",
            "AssertionError: Do not use tf.reset_default_graph() to clear nested graphs. If you need a cleared graph, exit the nesting and create a new graph.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 Accuracy: 0.2295999974012375\n",
            "Número de elementos en el conjunto etiquetado: 35478\n",
            "Epoch 1/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.0545 - loss: 4.1572\n",
            "Epoch 2/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.2105 - loss: 3.2136\n",
            "Epoch 3/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.2830 - loss: 2.8164\n",
            "Epoch 4/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3249 - loss: 2.5678\n",
            "Epoch 5/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3615 - loss: 2.3816\n",
            "Epoch 6/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3902 - loss: 2.2466\n",
            "Epoch 7/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4212 - loss: 2.1198\n",
            "Epoch 8/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4368 - loss: 2.0329\n",
            "Epoch 9/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4579 - loss: 1.9309\n",
            "Epoch 10/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4803 - loss: 1.8450\n",
            "Epoch 11/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4991 - loss: 1.7571\n",
            "Epoch 12/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5117 - loss: 1.7092\n",
            "Epoch 13/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5267 - loss: 1.6483\n",
            "Epoch 14/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5317 - loss: 1.6070\n",
            "Epoch 15/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5455 - loss: 1.5527\n",
            "Epoch 16/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5619 - loss: 1.4939\n",
            "Epoch 17/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5786 - loss: 1.4416\n",
            "Epoch 18/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5839 - loss: 1.4068\n",
            "Epoch 19/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6034 - loss: 1.3398\n",
            "Epoch 20/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6124 - loss: 1.3040\n",
            "Epoch 21/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6222 - loss: 1.2714\n",
            "Epoch 22/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6354 - loss: 1.2141\n",
            "Epoch 23/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6387 - loss: 1.1976\n",
            "Epoch 24/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6472 - loss: 1.1586\n",
            "Epoch 25/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6563 - loss: 1.1201\n",
            "Epoch 26/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6643 - loss: 1.0887\n",
            "Epoch 27/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6787 - loss: 1.0522\n",
            "Epoch 28/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6847 - loss: 1.0187\n",
            "Epoch 29/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6928 - loss: 0.9891\n",
            "Epoch 30/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7044 - loss: 0.9525\n",
            "Epoch 31/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7074 - loss: 0.9333\n",
            "Epoch 32/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7165 - loss: 0.9098\n",
            "Epoch 33/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7201 - loss: 0.8844\n",
            "Epoch 34/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7390 - loss: 0.8317\n",
            "Epoch 35/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7394 - loss: 0.8227\n",
            "Epoch 36/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7392 - loss: 0.8233\n",
            "Epoch 37/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7566 - loss: 0.7620\n",
            "Epoch 38/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7599 - loss: 0.7494\n",
            "Epoch 39/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7664 - loss: 0.7359\n",
            "Epoch 40/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7725 - loss: 0.7086\n",
            "Epoch 41/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7768 - loss: 0.6944\n",
            "Epoch 42/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7847 - loss: 0.6549\n",
            "Epoch 43/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7889 - loss: 0.6413\n",
            "Epoch 44/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7987 - loss: 0.6189\n",
            "Epoch 45/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7910 - loss: 0.6308\n",
            "Epoch 46/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8086 - loss: 0.5851\n",
            "Epoch 47/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8113 - loss: 0.5719\n",
            "Epoch 48/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8189 - loss: 0.5439\n",
            "Epoch 49/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8160 - loss: 0.5498\n",
            "Epoch 50/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8306 - loss: 0.5084\n",
            "Epoch 51/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8254 - loss: 0.5171\n",
            "Epoch 52/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8376 - loss: 0.4850\n",
            "Epoch 53/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8309 - loss: 0.4957\n",
            "Epoch 54/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8414 - loss: 0.4781\n",
            "Epoch 55/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8481 - loss: 0.4445\n",
            "Epoch 56/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8431 - loss: 0.4581\n",
            "Epoch 57/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8575 - loss: 0.4212\n",
            "Epoch 58/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8657 - loss: 0.3966\n",
            "Epoch 59/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8648 - loss: 0.3981\n",
            "Epoch 60/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8531 - loss: 0.4255\n",
            "Epoch 61/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8572 - loss: 0.4078\n",
            "Epoch 62/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8552 - loss: 0.4130\n",
            "Epoch 63/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8708 - loss: 0.3657\n",
            "Epoch 64/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8690 - loss: 0.3736\n",
            "Epoch 65/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8720 - loss: 0.3617\n",
            "Epoch 66/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8892 - loss: 0.3191\n",
            "Epoch 67/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8822 - loss: 0.3295\n",
            "Epoch 68/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8927 - loss: 0.3054\n",
            "Epoch 69/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8829 - loss: 0.3331\n",
            "Epoch 70/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8928 - loss: 0.3122\n",
            "Epoch 71/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8903 - loss: 0.3101\n",
            "Epoch 72/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8815 - loss: 0.3282\n",
            "Epoch 73/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8971 - loss: 0.2922\n",
            "Epoch 74/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8864 - loss: 0.3149\n",
            "Epoch 75/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8919 - loss: 0.3103\n",
            "Epoch 76/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9064 - loss: 0.2642\n",
            "Epoch 77/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8995 - loss: 0.2845\n",
            "Epoch 78/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8962 - loss: 0.2836\n",
            "Epoch 79/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8996 - loss: 0.2712\n",
            "Epoch 80/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8998 - loss: 0.2814\n",
            "Epoch 81/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9171 - loss: 0.2286\n",
            "Epoch 82/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9211 - loss: 0.2265\n",
            "Epoch 83/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9053 - loss: 0.2627\n",
            "Epoch 84/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9177 - loss: 0.2308\n",
            "Epoch 85/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8884 - loss: 0.3048\n",
            "Epoch 86/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9164 - loss: 0.2305\n",
            "Epoch 87/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9221 - loss: 0.2197\n",
            "Epoch 88/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9016 - loss: 0.2757\n",
            "Epoch 89/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9236 - loss: 0.2122\n",
            "Epoch 90/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9169 - loss: 0.2282\n",
            "Epoch 91/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9110 - loss: 0.2462\n",
            "Epoch 92/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9125 - loss: 0.2432\n",
            "Epoch 93/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9321 - loss: 0.1877\n",
            "Epoch 94/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9356 - loss: 0.1895\n",
            "Epoch 95/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9122 - loss: 0.2428\n",
            "Epoch 96/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9216 - loss: 0.2144\n",
            "Epoch 97/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9248 - loss: 0.2099\n",
            "Epoch 98/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9309 - loss: 0.1856\n",
            "Epoch 99/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9266 - loss: 0.2056\n",
            "Epoch 100/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9159 - loss: 0.2466\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "Epoch: 2 Accuracy: 0.21639999747276306\n",
            "Número de elementos en el conjunto etiquetado: 42677\n",
            "Epoch 1/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.0637 - loss: 4.0907\n",
            "Epoch 2/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.2195 - loss: 3.1416\n",
            "Epoch 3/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.2941 - loss: 2.7185\n",
            "Epoch 4/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3379 - loss: 2.4819\n",
            "Epoch 5/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3725 - loss: 2.3022\n",
            "Epoch 6/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3980 - loss: 2.1727\n",
            "Epoch 7/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4245 - loss: 2.0589\n",
            "Epoch 8/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4406 - loss: 1.9609\n",
            "Epoch 9/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4627 - loss: 1.8780\n",
            "Epoch 10/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4793 - loss: 1.8181\n",
            "Epoch 11/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4931 - loss: 1.7507\n",
            "Epoch 12/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5115 - loss: 1.6777\n",
            "Epoch 13/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5326 - loss: 1.6075\n",
            "Epoch 14/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5432 - loss: 1.5612\n",
            "Epoch 15/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5540 - loss: 1.5163\n",
            "Epoch 16/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5673 - loss: 1.4561\n",
            "Epoch 17/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5697 - loss: 1.4342\n",
            "Epoch 18/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5877 - loss: 1.3791\n",
            "Epoch 19/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5925 - loss: 1.3450\n",
            "Epoch 20/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6099 - loss: 1.2931\n",
            "Epoch 21/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6194 - loss: 1.2523\n",
            "Epoch 22/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6292 - loss: 1.2194\n",
            "Epoch 23/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6387 - loss: 1.1812\n",
            "Epoch 24/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6520 - loss: 1.1269\n",
            "Epoch 25/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6574 - loss: 1.1055\n",
            "Epoch 26/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6696 - loss: 1.0680\n",
            "Epoch 27/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6738 - loss: 1.0505\n",
            "Epoch 28/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6782 - loss: 1.0250\n",
            "Epoch 29/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6927 - loss: 0.9970\n",
            "Epoch 30/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7039 - loss: 0.9575\n",
            "Epoch 31/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7038 - loss: 0.9474\n",
            "Epoch 32/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7180 - loss: 0.8966\n",
            "Epoch 33/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7222 - loss: 0.8847\n",
            "Epoch 34/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7247 - loss: 0.8708\n",
            "Epoch 35/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7365 - loss: 0.8328\n",
            "Epoch 36/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7471 - loss: 0.7950\n",
            "Epoch 37/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7445 - loss: 0.7940\n",
            "Epoch 38/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7501 - loss: 0.7708\n",
            "Epoch 39/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7575 - loss: 0.7498\n",
            "Epoch 40/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7699 - loss: 0.7215\n",
            "Epoch 41/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7701 - loss: 0.7161\n",
            "Epoch 42/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7754 - loss: 0.6825\n",
            "Epoch 43/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7878 - loss: 0.6578\n",
            "Epoch 44/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7865 - loss: 0.6525\n",
            "Epoch 45/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7923 - loss: 0.6344\n",
            "Epoch 46/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8012 - loss: 0.6105\n",
            "Epoch 47/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8038 - loss: 0.5915\n",
            "Epoch 48/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8057 - loss: 0.5846\n",
            "Epoch 49/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8204 - loss: 0.5485\n",
            "Epoch 50/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8180 - loss: 0.5465\n",
            "Epoch 51/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8216 - loss: 0.5376\n",
            "Epoch 52/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8226 - loss: 0.5304\n",
            "Epoch 53/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8301 - loss: 0.5082\n",
            "Epoch 54/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8381 - loss: 0.4876\n",
            "Epoch 55/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8425 - loss: 0.4668\n",
            "Epoch 56/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8389 - loss: 0.4762\n",
            "Epoch 57/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8377 - loss: 0.4720\n",
            "Epoch 58/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8503 - loss: 0.4489\n",
            "Epoch 59/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8574 - loss: 0.4270\n",
            "Epoch 60/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8554 - loss: 0.4210\n",
            "Epoch 61/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8578 - loss: 0.4122\n",
            "Epoch 62/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8618 - loss: 0.4074\n",
            "Epoch 63/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8596 - loss: 0.4021\n",
            "Epoch 64/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8722 - loss: 0.3754\n",
            "Epoch 65/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8651 - loss: 0.3864\n",
            "Epoch 66/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8647 - loss: 0.3857\n",
            "Epoch 67/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8672 - loss: 0.3787\n",
            "Epoch 68/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8814 - loss: 0.3448\n",
            "Epoch 69/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8789 - loss: 0.3445\n",
            "Epoch 70/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8751 - loss: 0.3544\n",
            "Epoch 71/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8797 - loss: 0.3386\n",
            "Epoch 72/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8941 - loss: 0.3096\n",
            "Epoch 73/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8839 - loss: 0.3327\n",
            "Epoch 74/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8862 - loss: 0.3172\n",
            "Epoch 75/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8913 - loss: 0.3067\n",
            "Epoch 76/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8875 - loss: 0.3151\n",
            "Epoch 77/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8914 - loss: 0.3071\n",
            "Epoch 78/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9011 - loss: 0.2769\n",
            "Epoch 79/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8916 - loss: 0.2991\n",
            "Epoch 80/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8956 - loss: 0.2886\n",
            "Epoch 81/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9030 - loss: 0.2755\n",
            "Epoch 82/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8956 - loss: 0.2939\n",
            "Epoch 83/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8959 - loss: 0.2907\n",
            "Epoch 84/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9101 - loss: 0.2491\n",
            "Epoch 85/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9033 - loss: 0.2644\n",
            "Epoch 86/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9033 - loss: 0.2671\n",
            "Epoch 87/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9056 - loss: 0.2657\n",
            "Epoch 88/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9003 - loss: 0.2725\n",
            "Epoch 89/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9079 - loss: 0.2543\n",
            "Epoch 90/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9101 - loss: 0.2505\n",
            "Epoch 91/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9018 - loss: 0.2705\n",
            "Epoch 92/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9125 - loss: 0.2448\n",
            "Epoch 93/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9136 - loss: 0.2374\n",
            "Epoch 94/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9111 - loss: 0.2434\n",
            "Epoch 95/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9161 - loss: 0.2357\n",
            "Epoch 96/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9130 - loss: 0.2376\n",
            "Epoch 97/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9118 - loss: 0.2488\n",
            "Epoch 98/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9124 - loss: 0.2460\n",
            "Epoch 99/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9263 - loss: 0.2019\n",
            "Epoch 100/100\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9090 - loss: 0.2542\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "Epoch: 3 Accuracy: 0.2199999988079071\n",
            "Número de elementos en el conjunto etiquetado: 44794\n"
          ]
        }
      ],
      "source": [
        "model = self_training_v2(model_func, train_data, train_label, unlabelled_data_sin_atipicos, x_test, y_test, train_epochs=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Av4hEVDcYy8A",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Av4hEVDcYy8A",
        "outputId": "b4e12c6b-058f-4a59-d1b5-e634500d20f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.22\n"
          ]
        }
      ],
      "source": [
        "# Evaluamos en test\n",
        "test_acc = model.score(x_test, y_test)\n",
        "print('Test accuracy:', round(test_acc, 5))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "M8bLB2JgAUZl",
      "metadata": {
        "id": "M8bLB2JgAUZl"
      },
      "source": [
        "3. Modelo 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36YK36ZzAVTK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36YK36ZzAVTK",
        "outputId": "d5f6f9fc-1057-48fc-8781-1466a30b0fb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 24ms/step - loss: 0.0330\n",
            "Epoch 2/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 15ms/step - loss: 0.0108\n",
            "Epoch 3/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0083\n",
            "Epoch 4/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0074\n",
            "Epoch 5/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0067\n",
            "Epoch 6/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - loss: 0.0063\n",
            "Epoch 7/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0060\n",
            "Epoch 8/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - loss: 0.0058\n",
            "Epoch 9/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 0.0056\n",
            "Epoch 10/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.0054\n",
            "Epoch 11/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0052\n",
            "Epoch 12/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 0.0052\n",
            "Epoch 13/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0052\n",
            "Epoch 14/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0050\n",
            "Epoch 15/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0050\n",
            "Epoch 16/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0048\n",
            "Epoch 17/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.0047\n",
            "Epoch 18/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.0046\n",
            "Epoch 19/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0046\n",
            "Epoch 20/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0045\n",
            "Epoch 21/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 0.0044\n",
            "Epoch 22/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 0.0043\n",
            "Epoch 23/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.0043\n",
            "Epoch 24/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.0042\n",
            "Epoch 25/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0042\n",
            "Epoch 26/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 0.0041\n",
            "Epoch 27/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0040\n",
            "Epoch 28/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0040\n",
            "Epoch 29/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.0040\n",
            "Epoch 30/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.0039\n",
            "Epoch 31/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0039\n",
            "Epoch 32/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 0.0038\n",
            "Epoch 33/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 0.0038\n",
            "Epoch 34/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0037\n",
            "Epoch 35/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 0.0037\n",
            "Epoch 36/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 0.0036\n",
            "Epoch 37/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0036\n",
            "Epoch 38/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0036\n",
            "Epoch 39/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.0036\n",
            "Epoch 40/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.0035\n",
            "Epoch 41/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.0035\n",
            "Epoch 42/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0035\n",
            "Epoch 43/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 0.0034\n",
            "Epoch 44/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0034\n",
            "Epoch 45/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 0.0034\n",
            "Epoch 46/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0034\n",
            "Epoch 47/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0033\n",
            "Epoch 48/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0034\n",
            "Epoch 49/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0033\n",
            "Epoch 50/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 0.0033\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Epoch 1/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.0128 - loss: 4.6200\n",
            "Epoch 2/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0504 - loss: 4.2631\n",
            "Epoch 3/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0824 - loss: 4.0125\n",
            "Epoch 4/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1045 - loss: 3.8332\n",
            "Epoch 5/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1340 - loss: 3.6441\n",
            "Epoch 6/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1411 - loss: 3.5601\n",
            "Epoch 7/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1593 - loss: 3.4605\n",
            "Epoch 8/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1684 - loss: 3.3975\n",
            "Epoch 9/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1937 - loss: 3.3164\n",
            "Epoch 10/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1960 - loss: 3.2433\n",
            "Epoch 11/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2126 - loss: 3.1546\n",
            "Epoch 12/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2307 - loss: 3.0528\n",
            "Epoch 13/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2483 - loss: 2.9925\n",
            "Epoch 14/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2521 - loss: 2.9518\n",
            "Epoch 15/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2542 - loss: 2.9052\n",
            "Epoch 16/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2684 - loss: 2.8309\n",
            "Epoch 17/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2808 - loss: 2.7841\n",
            "Epoch 18/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2949 - loss: 2.7290\n",
            "Epoch 19/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3062 - loss: 2.6365\n",
            "Epoch 20/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3178 - loss: 2.6055\n",
            "Epoch 21/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3213 - loss: 2.5703\n",
            "Epoch 22/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3288 - loss: 2.5300\n",
            "Epoch 23/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3349 - loss: 2.4689\n",
            "Epoch 24/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3477 - loss: 2.4034\n",
            "Epoch 25/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3758 - loss: 2.3190\n",
            "Epoch 26/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3845 - loss: 2.2871\n",
            "Epoch 27/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4018 - loss: 2.2070\n",
            "Epoch 28/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4017 - loss: 2.1974\n",
            "Epoch 29/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4106 - loss: 2.1523\n",
            "Epoch 30/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4224 - loss: 2.1242\n",
            "Epoch 31/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4366 - loss: 2.0417\n",
            "Epoch 32/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4333 - loss: 2.0400\n",
            "Epoch 33/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4601 - loss: 1.9504\n",
            "Epoch 34/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4656 - loss: 1.9041\n",
            "Epoch 35/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4842 - loss: 1.8700\n",
            "Epoch 36/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4808 - loss: 1.8230\n",
            "Epoch 37/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5053 - loss: 1.7631\n",
            "Epoch 38/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5171 - loss: 1.7181\n",
            "Epoch 39/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5311 - loss: 1.6610\n",
            "Epoch 40/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5393 - loss: 1.6179\n",
            "Epoch 41/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5503 - loss: 1.5724\n",
            "Epoch 42/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5592 - loss: 1.5339\n",
            "Epoch 43/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5675 - loss: 1.5138\n",
            "Epoch 44/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6004 - loss: 1.4143\n",
            "Epoch 45/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5972 - loss: 1.4150\n",
            "Epoch 46/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6082 - loss: 1.3468\n",
            "Epoch 47/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6040 - loss: 1.3484\n",
            "Epoch 48/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6194 - loss: 1.3218\n",
            "Epoch 49/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6552 - loss: 1.2060\n",
            "Epoch 50/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6599 - loss: 1.1589\n",
            "Epoch 51/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6542 - loss: 1.1605\n",
            "Epoch 52/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6881 - loss: 1.0873\n",
            "Epoch 53/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6863 - loss: 1.0639\n",
            "Epoch 54/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6915 - loss: 1.0499\n",
            "Epoch 55/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6944 - loss: 1.0475\n",
            "Epoch 56/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7171 - loss: 0.9630\n",
            "Epoch 57/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7362 - loss: 0.9007\n",
            "Epoch 58/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7178 - loss: 0.9330\n",
            "Epoch 59/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7417 - loss: 0.8642\n",
            "Epoch 60/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7319 - loss: 0.8864\n",
            "Epoch 61/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7721 - loss: 0.7897\n",
            "Epoch 62/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7797 - loss: 0.7344\n",
            "Epoch 63/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7947 - loss: 0.7011\n",
            "Epoch 64/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7934 - loss: 0.6832\n",
            "Epoch 65/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8094 - loss: 0.6431\n",
            "Epoch 66/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7988 - loss: 0.6876\n",
            "Epoch 67/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8288 - loss: 0.5936\n",
            "Epoch 68/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8187 - loss: 0.5991\n",
            "Epoch 69/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.5327\n",
            "Epoch 70/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8433 - loss: 0.5385\n",
            "Epoch 71/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.5115\n",
            "Epoch 72/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8328 - loss: 0.5437\n",
            "Epoch 73/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.5037\n",
            "Epoch 74/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8579 - loss: 0.4690\n",
            "Epoch 75/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8693 - loss: 0.4471\n",
            "Epoch 76/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8887 - loss: 0.3834\n",
            "Epoch 77/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8880 - loss: 0.3874\n",
            "Epoch 78/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8984 - loss: 0.3599\n",
            "Epoch 79/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8925 - loss: 0.3599\n",
            "Epoch 80/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8653 - loss: 0.4285\n",
            "Epoch 81/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8906 - loss: 0.3514\n",
            "Epoch 82/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9139 - loss: 0.3124\n",
            "Epoch 83/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9069 - loss: 0.3062\n",
            "Epoch 84/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9295 - loss: 0.2536\n",
            "Epoch 85/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9347 - loss: 0.2410\n",
            "Epoch 86/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9206 - loss: 0.2627\n",
            "Epoch 87/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8639 - loss: 0.4132\n",
            "Epoch 88/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8588 - loss: 0.4197\n",
            "Epoch 89/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9254 - loss: 0.2448\n",
            "Epoch 90/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9514 - loss: 0.1872\n",
            "Epoch 91/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9520 - loss: 0.1785\n",
            "Epoch 92/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9186 - loss: 0.2620\n",
            "Epoch 93/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9055 - loss: 0.2954\n",
            "Epoch 94/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8791 - loss: 0.3509\n",
            "Epoch 95/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9017 - loss: 0.3023\n",
            "Epoch 96/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9495 - loss: 0.1799\n",
            "Epoch 97/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9620 - loss: 0.1514\n",
            "Epoch 98/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9678 - loss: 0.1244\n",
            "Epoch 99/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9747 - loss: 0.1094\n",
            "Epoch 100/100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9801 - loss: 0.0930\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(<__main__.MiAutoencoder at 0x7e390b0e60d0>,\n",
              " <__main__.MiClasificador at 0x7e39094180d0>)"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semisupervised_training(autoencoder, classifier, train_data, train_label, unlabelled_data_sin_atipicos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "D842WJ_naDj-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D842WJ_naDj-",
        "outputId": "0e41597c-936e-45e1-a021-2d327a787c5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "Test accuracy : 0.19519999623298645\n"
          ]
        }
      ],
      "source": [
        "# Evaluamos en test\n",
        "pred_test = autoencoder.get_encoded_data(x_test)\n",
        "print('Test accuracy :', classifier.score(pred_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pDOXQ-XQAYYk",
      "metadata": {
        "id": "pDOXQ-XQAYYk"
      },
      "source": [
        "4. Modelo 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fbQxBa1AZYe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fbQxBa1AZYe",
        "outputId": "c7054d7b-4d7b-4c33-dee8-9d004f077aa4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 23ms/step - dense_accuracy: 0.0071 - dense_loss: 0.9707 - flatten_accuracy: 0.0013 - flatten_loss: 0.0122 - loss: 0.9829\n",
            "Epoch 2/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.0427 - dense_loss: 0.8221 - flatten_accuracy: 0.0028 - flatten_loss: 0.0070 - loss: 0.8291\n",
            "Epoch 3/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.0518 - dense_loss: 0.7247 - flatten_accuracy: 0.0025 - flatten_loss: 0.0062 - loss: 0.7310\n",
            "Epoch 4/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.0674 - dense_loss: 0.6582 - flatten_accuracy: 0.0036 - flatten_loss: 0.0056 - loss: 0.6638\n",
            "Epoch 5/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - dense_accuracy: 0.0782 - dense_loss: 0.5992 - flatten_accuracy: 0.0037 - flatten_loss: 0.0053 - loss: 0.6045\n",
            "Epoch 6/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.0962 - dense_loss: 0.5144 - flatten_accuracy: 0.0042 - flatten_loss: 0.0050 - loss: 0.5194\n",
            "Epoch 7/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - dense_accuracy: 0.1121 - dense_loss: 0.4389 - flatten_accuracy: 0.0040 - flatten_loss: 0.0049 - loss: 0.4438\n",
            "Epoch 8/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.1272 - dense_loss: 0.3578 - flatten_accuracy: 0.0052 - flatten_loss: 0.0046 - loss: 0.3625\n",
            "Epoch 9/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.1419 - dense_loss: 0.3004 - flatten_accuracy: 0.0046 - flatten_loss: 0.0046 - loss: 0.3051\n",
            "Epoch 10/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.1561 - dense_loss: 0.2484 - flatten_accuracy: 0.0053 - flatten_loss: 0.0045 - loss: 0.2529\n",
            "Epoch 11/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.1745 - dense_loss: 0.1955 - flatten_accuracy: 0.0049 - flatten_loss: 0.0046 - loss: 0.2000\n",
            "Epoch 12/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.1845 - dense_loss: 0.1506 - flatten_accuracy: 0.0049 - flatten_loss: 0.0044 - loss: 0.1549\n",
            "Epoch 13/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.1937 - dense_loss: 0.1058 - flatten_accuracy: 0.0060 - flatten_loss: 0.0044 - loss: 0.1102\n",
            "Epoch 14/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2022 - dense_loss: 0.0819 - flatten_accuracy: 0.0055 - flatten_loss: 0.0043 - loss: 0.0862\n",
            "Epoch 15/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2067 - dense_loss: 0.0664 - flatten_accuracy: 0.0053 - flatten_loss: 0.0043 - loss: 0.0707\n",
            "Epoch 16/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2059 - dense_loss: 0.0580 - flatten_accuracy: 0.0057 - flatten_loss: 0.0042 - loss: 0.0622\n",
            "Epoch 17/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - dense_accuracy: 0.2115 - dense_loss: 0.0479 - flatten_accuracy: 0.0060 - flatten_loss: 0.0042 - loss: 0.0520\n",
            "Epoch 18/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2112 - dense_loss: 0.0474 - flatten_accuracy: 0.0059 - flatten_loss: 0.0043 - loss: 0.0517\n",
            "Epoch 19/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - dense_accuracy: 0.2148 - dense_loss: 0.0410 - flatten_accuracy: 0.0053 - flatten_loss: 0.0042 - loss: 0.0451\n",
            "Epoch 20/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2147 - dense_loss: 0.0438 - flatten_accuracy: 0.0054 - flatten_loss: 0.0042 - loss: 0.0480\n",
            "Epoch 21/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2150 - dense_loss: 0.0311 - flatten_accuracy: 0.0060 - flatten_loss: 0.0040 - loss: 0.0352\n",
            "Epoch 22/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2135 - dense_loss: 0.0332 - flatten_accuracy: 0.0057 - flatten_loss: 0.0040 - loss: 0.0372\n",
            "Epoch 23/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2179 - dense_loss: 0.0325 - flatten_accuracy: 0.0049 - flatten_loss: 0.0041 - loss: 0.0366\n",
            "Epoch 24/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2181 - dense_loss: 0.0287 - flatten_accuracy: 0.0053 - flatten_loss: 0.0040 - loss: 0.0328\n",
            "Epoch 25/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2171 - dense_loss: 0.0323 - flatten_accuracy: 0.0061 - flatten_loss: 0.0040 - loss: 0.0363\n",
            "Epoch 26/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2162 - dense_loss: 0.0296 - flatten_accuracy: 0.0062 - flatten_loss: 0.0040 - loss: 0.0336\n",
            "Epoch 27/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2187 - dense_loss: 0.0313 - flatten_accuracy: 0.0059 - flatten_loss: 0.0041 - loss: 0.0353\n",
            "Epoch 28/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2213 - dense_loss: 0.0290 - flatten_accuracy: 0.0059 - flatten_loss: 0.0040 - loss: 0.0330\n",
            "Epoch 29/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - dense_accuracy: 0.2195 - dense_loss: 0.0202 - flatten_accuracy: 0.0062 - flatten_loss: 0.0039 - loss: 0.0241\n",
            "Epoch 30/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2177 - dense_loss: 0.0243 - flatten_accuracy: 0.0054 - flatten_loss: 0.0040 - loss: 0.0283\n",
            "Epoch 31/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2238 - dense_loss: 0.0249 - flatten_accuracy: 0.0057 - flatten_loss: 0.0041 - loss: 0.0289\n",
            "Epoch 32/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2190 - dense_loss: 0.0193 - flatten_accuracy: 0.0053 - flatten_loss: 0.0039 - loss: 0.0232\n",
            "Epoch 33/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2230 - dense_loss: 0.0183 - flatten_accuracy: 0.0057 - flatten_loss: 0.0039 - loss: 0.0222\n",
            "Epoch 34/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2218 - dense_loss: 0.0236 - flatten_accuracy: 0.0067 - flatten_loss: 0.0040 - loss: 0.0275\n",
            "Epoch 35/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - dense_accuracy: 0.2126 - dense_loss: 0.0385 - flatten_accuracy: 0.0057 - flatten_loss: 0.0041 - loss: 0.0426\n",
            "Epoch 36/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2193 - dense_loss: 0.0167 - flatten_accuracy: 0.0052 - flatten_loss: 0.0038 - loss: 0.0206\n",
            "Epoch 37/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2260 - dense_loss: 0.0172 - flatten_accuracy: 0.0055 - flatten_loss: 0.0038 - loss: 0.0210\n",
            "Epoch 38/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2226 - dense_loss: 0.0192 - flatten_accuracy: 0.0059 - flatten_loss: 0.0039 - loss: 0.0232\n",
            "Epoch 39/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2198 - dense_loss: 0.0197 - flatten_accuracy: 0.0059 - flatten_loss: 0.0038 - loss: 0.0236\n",
            "Epoch 40/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2177 - dense_loss: 0.0228 - flatten_accuracy: 0.0058 - flatten_loss: 0.0039 - loss: 0.0267\n",
            "Epoch 41/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2188 - dense_loss: 0.0188 - flatten_accuracy: 0.0064 - flatten_loss: 0.0039 - loss: 0.0227\n",
            "Epoch 42/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2219 - dense_loss: 0.0157 - flatten_accuracy: 0.0060 - flatten_loss: 0.0038 - loss: 0.0194\n",
            "Epoch 43/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2228 - dense_loss: 0.0110 - flatten_accuracy: 0.0061 - flatten_loss: 0.0038 - loss: 0.0148\n",
            "Epoch 44/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2162 - dense_loss: 0.0283 - flatten_accuracy: 0.0058 - flatten_loss: 0.0039 - loss: 0.0322\n",
            "Epoch 45/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2175 - dense_loss: 0.0282 - flatten_accuracy: 0.0058 - flatten_loss: 0.0039 - loss: 0.0321\n",
            "Epoch 46/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2190 - dense_loss: 0.0176 - flatten_accuracy: 0.0061 - flatten_loss: 0.0039 - loss: 0.0215\n",
            "Epoch 47/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2207 - dense_loss: 0.0153 - flatten_accuracy: 0.0063 - flatten_loss: 0.0037 - loss: 0.0191\n",
            "Epoch 48/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - dense_accuracy: 0.2244 - dense_loss: 0.0153 - flatten_accuracy: 0.0060 - flatten_loss: 0.0039 - loss: 0.0193\n",
            "Epoch 49/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2245 - dense_loss: 0.0135 - flatten_accuracy: 0.0052 - flatten_loss: 0.0038 - loss: 0.0173\n",
            "Epoch 50/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2212 - dense_loss: 0.0231 - flatten_accuracy: 0.0057 - flatten_loss: 0.0039 - loss: 0.0271\n",
            "Epoch 51/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2245 - dense_loss: 0.0135 - flatten_accuracy: 0.0056 - flatten_loss: 0.0038 - loss: 0.0173\n",
            "Epoch 52/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - dense_accuracy: 0.2245 - dense_loss: 0.0178 - flatten_accuracy: 0.0054 - flatten_loss: 0.0039 - loss: 0.0217\n",
            "Epoch 53/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - dense_accuracy: 0.2230 - dense_loss: 0.0240 - flatten_accuracy: 0.0058 - flatten_loss: 0.0039 - loss: 0.0280\n",
            "Epoch 54/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2196 - dense_loss: 0.0092 - flatten_accuracy: 0.0057 - flatten_loss: 0.0036 - loss: 0.0128\n",
            "Epoch 55/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2209 - dense_loss: 0.0119 - flatten_accuracy: 0.0069 - flatten_loss: 0.0036 - loss: 0.0155\n",
            "Epoch 56/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2224 - dense_loss: 0.0094 - flatten_accuracy: 0.0058 - flatten_loss: 0.0037 - loss: 0.0131\n",
            "Epoch 57/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2201 - dense_loss: 0.0272 - flatten_accuracy: 0.0054 - flatten_loss: 0.0039 - loss: 0.0311\n",
            "Epoch 58/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2224 - dense_loss: 0.0182 - flatten_accuracy: 0.0064 - flatten_loss: 0.0039 - loss: 0.0221\n",
            "Epoch 59/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2201 - dense_loss: 0.0189 - flatten_accuracy: 0.0053 - flatten_loss: 0.0039 - loss: 0.0228\n",
            "Epoch 60/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - dense_accuracy: 0.2239 - dense_loss: 0.0169 - flatten_accuracy: 0.0061 - flatten_loss: 0.0039 - loss: 0.0207\n",
            "Epoch 61/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 19ms/step - dense_accuracy: 0.2265 - dense_loss: 0.0155 - flatten_accuracy: 0.0058 - flatten_loss: 0.0038 - loss: 0.0193\n",
            "Epoch 62/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - dense_accuracy: 0.2211 - dense_loss: 0.0116 - flatten_accuracy: 0.0055 - flatten_loss: 0.0038 - loss: 0.0154\n",
            "Epoch 63/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - dense_accuracy: 0.2218 - dense_loss: 0.0182 - flatten_accuracy: 0.0064 - flatten_loss: 0.0037 - loss: 0.0219\n",
            "Epoch 64/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - dense_accuracy: 0.2221 - dense_loss: 0.0095 - flatten_accuracy: 0.0064 - flatten_loss: 0.0036 - loss: 0.0131\n",
            "Epoch 65/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2204 - dense_loss: 0.0182 - flatten_accuracy: 0.0055 - flatten_loss: 0.0038 - loss: 0.0220\n",
            "Epoch 66/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2243 - dense_loss: 0.0185 - flatten_accuracy: 0.0055 - flatten_loss: 0.0037 - loss: 0.0223\n",
            "Epoch 67/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - dense_accuracy: 0.2260 - dense_loss: 0.0151 - flatten_accuracy: 0.0060 - flatten_loss: 0.0038 - loss: 0.0189\n",
            "Epoch 68/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2245 - dense_loss: 0.0089 - flatten_accuracy: 0.0066 - flatten_loss: 0.0037 - loss: 0.0126\n",
            "Epoch 69/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2232 - dense_loss: 0.0142 - flatten_accuracy: 0.0060 - flatten_loss: 0.0038 - loss: 0.0180\n",
            "Epoch 70/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2189 - dense_loss: 0.0172 - flatten_accuracy: 0.0059 - flatten_loss: 0.0037 - loss: 0.0210\n",
            "Epoch 71/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2201 - dense_loss: 0.0168 - flatten_accuracy: 0.0069 - flatten_loss: 0.0038 - loss: 0.0205\n",
            "Epoch 72/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2231 - dense_loss: 0.0158 - flatten_accuracy: 0.0058 - flatten_loss: 0.0039 - loss: 0.0197\n",
            "Epoch 73/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2263 - dense_loss: 0.0096 - flatten_accuracy: 0.0067 - flatten_loss: 0.0037 - loss: 0.0133\n",
            "Epoch 74/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - dense_accuracy: 0.2255 - dense_loss: 0.0133 - flatten_accuracy: 0.0065 - flatten_loss: 0.0038 - loss: 0.0171\n",
            "Epoch 75/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - dense_accuracy: 0.2191 - dense_loss: 0.0284 - flatten_accuracy: 0.0056 - flatten_loss: 0.0040 - loss: 0.0323\n",
            "Epoch 76/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2195 - dense_loss: 0.0140 - flatten_accuracy: 0.0063 - flatten_loss: 0.0038 - loss: 0.0178\n",
            "Epoch 77/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2227 - dense_loss: 0.0137 - flatten_accuracy: 0.0058 - flatten_loss: 0.0038 - loss: 0.0175\n",
            "Epoch 78/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2232 - dense_loss: 0.0093 - flatten_accuracy: 0.0070 - flatten_loss: 0.0037 - loss: 0.0130\n",
            "Epoch 79/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2243 - dense_loss: 0.0076 - flatten_accuracy: 0.0051 - flatten_loss: 0.0037 - loss: 0.0112\n",
            "Epoch 80/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2168 - dense_loss: 0.0216 - flatten_accuracy: 0.0057 - flatten_loss: 0.0037 - loss: 0.0253\n",
            "Epoch 81/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2237 - dense_loss: 0.0141 - flatten_accuracy: 0.0060 - flatten_loss: 0.0038 - loss: 0.0179\n",
            "Epoch 82/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2218 - dense_loss: 0.0159 - flatten_accuracy: 0.0056 - flatten_loss: 0.0037 - loss: 0.0196\n",
            "Epoch 83/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2232 - dense_loss: 0.0147 - flatten_accuracy: 0.0058 - flatten_loss: 0.0038 - loss: 0.0185\n",
            "Epoch 84/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2222 - dense_loss: 0.0149 - flatten_accuracy: 0.0069 - flatten_loss: 0.0037 - loss: 0.0186\n",
            "Epoch 85/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2251 - dense_loss: 0.0076 - flatten_accuracy: 0.0059 - flatten_loss: 0.0036 - loss: 0.0112\n",
            "Epoch 86/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2169 - dense_loss: 0.0116 - flatten_accuracy: 0.0061 - flatten_loss: 0.0037 - loss: 0.0153\n",
            "Epoch 87/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2263 - dense_loss: 0.0143 - flatten_accuracy: 0.0057 - flatten_loss: 0.0039 - loss: 0.0182\n",
            "Epoch 88/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2243 - dense_loss: 0.0070 - flatten_accuracy: 0.0063 - flatten_loss: 0.0037 - loss: 0.0106\n",
            "Epoch 89/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2227 - dense_loss: 0.0065 - flatten_accuracy: 0.0063 - flatten_loss: 0.0036 - loss: 0.0101\n",
            "Epoch 90/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2251 - dense_loss: 0.0163 - flatten_accuracy: 0.0053 - flatten_loss: 0.0038 - loss: 0.0201\n",
            "Epoch 91/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2209 - dense_loss: 0.0224 - flatten_accuracy: 0.0058 - flatten_loss: 0.0038 - loss: 0.0263\n",
            "Epoch 92/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2246 - dense_loss: 0.0066 - flatten_accuracy: 0.0055 - flatten_loss: 0.0036 - loss: 0.0102\n",
            "Epoch 93/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2249 - dense_loss: 0.0062 - flatten_accuracy: 0.0062 - flatten_loss: 0.0036 - loss: 0.0098\n",
            "Epoch 94/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - dense_accuracy: 0.2274 - dense_loss: 0.0086 - flatten_accuracy: 0.0059 - flatten_loss: 0.0037 - loss: 0.0122\n",
            "Epoch 95/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2260 - dense_loss: 0.0147 - flatten_accuracy: 0.0052 - flatten_loss: 0.0037 - loss: 0.0185\n",
            "Epoch 96/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2210 - dense_loss: 0.0144 - flatten_accuracy: 0.0057 - flatten_loss: 0.0037 - loss: 0.0182\n",
            "Epoch 97/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2192 - dense_loss: 0.0180 - flatten_accuracy: 0.0056 - flatten_loss: 0.0038 - loss: 0.0218\n",
            "Epoch 98/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2216 - dense_loss: 0.0116 - flatten_accuracy: 0.0058 - flatten_loss: 0.0037 - loss: 0.0153\n",
            "Epoch 99/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - dense_accuracy: 0.2248 - dense_loss: 0.0125 - flatten_accuracy: 0.0051 - flatten_loss: 0.0037 - loss: 0.0162\n",
            "Epoch 100/100\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_accuracy: 0.2238 - dense_loss: 0.0121 - flatten_accuracy: 0.0063 - flatten_loss: 0.0037 - loss: 0.0158\n"
          ]
        }
      ],
      "source": [
        "model = MiClasificadorSemisupervisado(input_shape=(32*32*3, ))\n",
        "semisupervised_training_v2(model, train_data, train_label, unlabelled_data_sin_atipicos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-Ppmln8kaRHr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ppmln8kaRHr",
        "outputId": "43a040d6-3f40-4fbe-dc97-027d4a8847db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - dense_accuracy: 0.1943 - dense_loss: 18.8466 - flatten_accuracy: 0.0077 - flatten_loss: 0.0241 - loss: 18.8707\n",
            "Test accuracy : 0.19550000131130219\n"
          ]
        }
      ],
      "source": [
        "x_test = x_test.reshape(x_test.shape[0], (32*32*3))\n",
        "print('Test accuracy :', model.score(x_test, y_test)[3])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_ur62LYzfdKC",
      "metadata": {
        "id": "_ur62LYzfdKC"
      },
      "source": [
        "<u>Responde a la siguiente pregunta:</u>\n",
        "\n",
        "1. ¿Se mejoran los resultados?\n",
        "\n",
        "  - En el modelo 2, se mantiene más o menos igual (0.22)\n",
        "\n",
        "  - En el modelo 3, la precisión es de 0.19, igual que antes de eliminar atípicos.\n",
        "\n",
        "  - En el modelo 3, baja la precisión en 0.01\n",
        "\n",
        "  No se aprecian mejoras significativas"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "o2aoJ3Ncfaxt",
      "metadata": {
        "id": "o2aoJ3Ncfaxt"
      },
      "source": [
        "### Cambiamos el Autoencoder por otra técnica"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "X4-hanIhg872",
      "metadata": {
        "id": "X4-hanIhg872"
      },
      "outputs": [],
      "source": [
        "class ContrastiveLearning(tf.keras.Model):\n",
        "    def __init__(self, input_shape, num_classes, lamda, tau):\n",
        "        super(ContrastiveLearning, self).__init__()\n",
        "\n",
        "        self.tau = tau\n",
        "        self.lamda = lamda\n",
        "        self.loss_tracker = tf.keras.metrics.Mean(name='loss')\n",
        "\n",
        "        # Data augmentation\n",
        "        self.data_augmentation = tf.keras.Sequential([\n",
        "            tf.keras.layers.RandomRotation(0.02),\n",
        "            tf.keras.layers.RandomTranslation(0.15, 0.15),\n",
        "            tf.keras.layers.RandomZoom(0.15)\n",
        "        ])\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = tf.keras.Sequential([\n",
        "            tf.keras.layers.InputLayer(input_shape=input_shape),\n",
        "            tf.keras.layers.Conv2D(16, (3, 3), activation='relu'),\n",
        "            tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "            tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "            tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        ])\n",
        "\n",
        "        # Clasificador\n",
        "        self.classifier = tf.keras.Sequential([\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "        ])\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.loss_tracker]\n",
        "\n",
        "    def train_step(self, data):\n",
        "        augmented_1, augmented_2 = self.data_augmentation(data), self.data_augmentation(data)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "\n",
        "            # Encoder\n",
        "            z_1 = self.encoder(augmented_1, training=True)\n",
        "            z_2 = self.encoder(augmented_2, training=True)\n",
        "\n",
        "            # Normalizamos los vectores\n",
        "            z_1 = self.normalize(z_1)\n",
        "            z_2 = self.normalize(z_2)\n",
        "\n",
        "            # Classifier\n",
        "            y_1 = self.classifier(z_1, training=True)\n",
        "            y_2 = self.classifier(z_2, training=True)\n",
        "\n",
        "            # Loss\n",
        "            loss = self.compute_loss(z_1, z_2, y_1, y_2, self.lamda, self.tau)\n",
        "\n",
        "        # Actualizar\n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "        self.loss_tracker.update_state(loss)\n",
        "        return {'loss': self.loss_tracker.result()}\n",
        "\n",
        "    def normalize(self, x):\n",
        "        return (x-tf.reduce_mean(x, axis=0)) / (tf.math.reduce_std(x, axis=0) + 1e-8)\n",
        "\n",
        "    def compute_loss(self, z_1, z_2, y_1, y_2, lamda, tau):\n",
        "        batch_size, d = tf.shape(z_1)[0], tf.shape(z_1)[1]\n",
        "\n",
        "        z_1 = tf.reshape(z_1, (batch_size, -1, 1))\n",
        "        z_2 = tf.reshape(z_2, (batch_size, -1, 1))\n",
        "\n",
        "\n",
        "        # matriz de correlación cruzada\n",
        "        C = tf.matmul(z_1, z_2, transpose_b=True)\n",
        "        C = tf.cast(C, tf.float32)\n",
        "\n",
        "        # Matriz identidad\n",
        "        dim = tf.shape(C)[1]\n",
        "        I = tf.eye(num_rows=dim, num_columns=dim, batch_shape=[batch_size])\n",
        "\n",
        "\n",
        "        # Loss Lm\n",
        "        softmax_matrix = tf.nn.softmax(C / tau, axis=1)\n",
        "        loss_Lm = tf.keras.losses.categorical_crossentropy(I, softmax_matrix, from_logits=False, axis=1)\n",
        "\n",
        "        Loss_Ly = tf.reduce_mean(y_1*(1-y_1) + y_2*(1-y_2))\n",
        "\n",
        "        loss = loss_Lm + lamda * Loss_Ly\n",
        "        return loss\n",
        "\n",
        "    def get_encoded_data(self, X):\n",
        "        z = self.encoder.predict(X)\n",
        "        z = self.normalize(z)\n",
        "        return z\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vIbHBp_W7hEX",
      "metadata": {
        "id": "vIbHBp_W7hEX"
      },
      "source": [
        "Creamos el modelo y entrenamos con todos los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "EiEdvRZ41rzZ",
      "metadata": {
        "id": "EiEdvRZ41rzZ"
      },
      "outputs": [],
      "source": [
        "model = ContrastiveLearning(input_shape=(32, 32, 3), num_classes=NUM_CLASES, lamda=0.5, tau=5)\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=opt)\n",
        "\n",
        "classifier = MiClasificador()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "wKxLC76726qD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKxLC76726qD",
        "outputId": "5e1c149f-6d4e-4c28-b233-d174de608ba7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 187ms/step - loss: 7.5034\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Epoch 1/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.0214 - loss: 4.6269\n",
            "Epoch 2/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0360 - loss: 4.3976\n",
            "Epoch 3/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0530 - loss: 4.2606\n",
            "Epoch 4/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0592 - loss: 4.1524\n",
            "Epoch 5/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0740 - loss: 4.0984\n",
            "Epoch 6/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0778 - loss: 4.0093\n",
            "Epoch 7/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0892 - loss: 3.9773\n",
            "Epoch 8/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1015 - loss: 3.9224\n",
            "Epoch 9/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1018 - loss: 3.8616\n",
            "Epoch 10/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1151 - loss: 3.7961\n",
            "Epoch 11/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1136 - loss: 3.7540\n",
            "Epoch 12/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1310 - loss: 3.6956\n",
            "Epoch 13/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1387 - loss: 3.6558\n",
            "Epoch 14/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1478 - loss: 3.5899\n",
            "Epoch 15/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1532 - loss: 3.5367\n",
            "Epoch 16/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1484 - loss: 3.4993\n",
            "Epoch 17/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1721 - loss: 3.4414\n",
            "Epoch 18/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1702 - loss: 3.3731\n",
            "Epoch 19/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1908 - loss: 3.2953\n",
            "Epoch 20/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1901 - loss: 3.2895\n",
            "Epoch 21/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2107 - loss: 3.2237\n",
            "Epoch 22/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2015 - loss: 3.2094\n",
            "Epoch 23/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2185 - loss: 3.1411\n",
            "Epoch 24/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2338 - loss: 3.0635\n",
            "Epoch 25/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2411 - loss: 3.0269\n",
            "Epoch 26/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2474 - loss: 2.9957\n",
            "Epoch 27/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2526 - loss: 2.9609\n",
            "Epoch 28/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2654 - loss: 2.9212\n",
            "Epoch 29/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2739 - loss: 2.8705\n",
            "Epoch 30/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2904 - loss: 2.7828\n",
            "Epoch 31/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3007 - loss: 2.7749\n",
            "Epoch 32/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3047 - loss: 2.7155\n",
            "Epoch 33/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3155 - loss: 2.6646\n",
            "Epoch 34/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3262 - loss: 2.6073\n",
            "Epoch 35/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3397 - loss: 2.5969\n",
            "Epoch 36/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3397 - loss: 2.5509\n",
            "Epoch 37/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3506 - loss: 2.5182\n",
            "Epoch 38/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3728 - loss: 2.4467\n",
            "Epoch 39/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3724 - loss: 2.4014\n",
            "Epoch 40/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3875 - loss: 2.3627\n",
            "Epoch 41/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3903 - loss: 2.3318\n",
            "Epoch 42/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3970 - loss: 2.3202\n",
            "Epoch 43/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4182 - loss: 2.2222\n",
            "Epoch 44/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4145 - loss: 2.2349\n",
            "Epoch 45/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4187 - loss: 2.2222\n",
            "Epoch 46/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4365 - loss: 2.1656\n",
            "Epoch 47/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4419 - loss: 2.1330\n",
            "Epoch 48/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4433 - loss: 2.1162\n",
            "Epoch 49/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4652 - loss: 2.0313\n",
            "Epoch 50/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4610 - loss: 2.0493\n",
            "Epoch 51/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4653 - loss: 2.0287\n",
            "Epoch 52/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4818 - loss: 1.9661\n",
            "Epoch 53/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4875 - loss: 1.9522\n",
            "Epoch 54/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4841 - loss: 1.9425\n",
            "Epoch 55/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4962 - loss: 1.9137\n",
            "Epoch 56/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5005 - loss: 1.8795\n",
            "Epoch 57/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5116 - loss: 1.8667\n",
            "Epoch 58/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5038 - loss: 1.8236\n",
            "Epoch 59/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5106 - loss: 1.8516\n",
            "Epoch 60/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5339 - loss: 1.7480\n",
            "Epoch 61/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5289 - loss: 1.7603\n",
            "Epoch 62/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5389 - loss: 1.7250\n",
            "Epoch 63/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5409 - loss: 1.7360\n",
            "Epoch 64/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5502 - loss: 1.7009\n",
            "Epoch 65/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5531 - loss: 1.6648\n",
            "Epoch 66/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5531 - loss: 1.6601\n",
            "Epoch 67/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5644 - loss: 1.6258\n",
            "Epoch 68/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5753 - loss: 1.5869\n",
            "Epoch 69/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5847 - loss: 1.5617\n",
            "Epoch 70/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5671 - loss: 1.6006\n",
            "Epoch 71/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5834 - loss: 1.5519\n",
            "Epoch 72/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5871 - loss: 1.5301\n",
            "Epoch 73/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5839 - loss: 1.5282\n",
            "Epoch 74/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5837 - loss: 1.5268\n",
            "Epoch 75/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5943 - loss: 1.5018\n",
            "Epoch 76/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6033 - loss: 1.4765\n",
            "Epoch 77/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6203 - loss: 1.4077\n",
            "Epoch 78/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6084 - loss: 1.4390\n",
            "Epoch 79/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6196 - loss: 1.4133\n",
            "Epoch 80/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6126 - loss: 1.4318\n",
            "Epoch 81/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6138 - loss: 1.4150\n",
            "Epoch 82/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6237 - loss: 1.3979\n",
            "Epoch 83/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6311 - loss: 1.3524\n",
            "Epoch 84/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6351 - loss: 1.3448\n",
            "Epoch 85/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6264 - loss: 1.3784\n",
            "Epoch 86/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6330 - loss: 1.3480\n",
            "Epoch 87/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6263 - loss: 1.3647\n",
            "Epoch 88/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6361 - loss: 1.3057\n",
            "Epoch 89/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6445 - loss: 1.2737\n",
            "Epoch 90/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6389 - loss: 1.3125\n",
            "Epoch 91/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6520 - loss: 1.2613\n",
            "Epoch 92/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6572 - loss: 1.2619\n",
            "Epoch 93/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6572 - loss: 1.2333\n",
            "Epoch 94/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6679 - loss: 1.1950\n",
            "Epoch 95/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6599 - loss: 1.2293\n",
            "Epoch 96/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6489 - loss: 1.2467\n",
            "Epoch 97/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6509 - loss: 1.2502\n",
            "Epoch 98/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6588 - loss: 1.2258\n",
            "Epoch 99/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6620 - loss: 1.2066\n",
            "Epoch 100/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6647 - loss: 1.1961\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(<ContrastiveLearning name=contrastive_learning_1, built=False>,\n",
              " <__main__.MiClasificador at 0x7d3cfff69510>)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semisupervised_training(model, classifier, train_data, train_label, unlabelled_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "-eZguVnD4959",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eZguVnD4959",
        "outputId": "fd15f6bb-de8f-471d-b94c-b49f6e669ff8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "Test accuracy : 0.10220000147819519\n"
          ]
        }
      ],
      "source": [
        "pred = model.get_encoded_data(x_test)\n",
        "print('Test accuracy :', classifier.score(pred, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pHQkln1w8Nun",
      "metadata": {
        "id": "pHQkln1w8Nun"
      },
      "source": [
        "Probamos con el conjunto con los datos atípicos eliminados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "FWOQXsUU4_k3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWOQXsUU4_k3",
        "outputId": "335078d9-5ae9-48be-80b4-59a0d356b6d5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model = ContrastiveLearning(input_shape=(32, 32, 3), num_classes=NUM_CLASES, lamda=0.5, tau=0.1)\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=opt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "ZA5ZAMTk5BKv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZA5ZAMTk5BKv",
        "outputId": "5b6b9238-f5a7-4a4b-b254-1b0ba38bab90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1434/1434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 186ms/step - loss: 7.7651\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Epoch 1/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0184 - loss: 5.0159\n",
            "Epoch 2/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0279 - loss: 4.4732\n",
            "Epoch 3/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0343 - loss: 4.3890\n",
            "Epoch 4/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0328 - loss: 4.3563\n",
            "Epoch 5/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0367 - loss: 4.3298\n",
            "Epoch 6/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0390 - loss: 4.2953\n",
            "Epoch 7/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0458 - loss: 4.2723\n",
            "Epoch 8/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0519 - loss: 4.2445\n",
            "Epoch 9/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0462 - loss: 4.2295\n",
            "Epoch 10/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0531 - loss: 4.2135\n",
            "Epoch 11/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0496 - loss: 4.1826\n",
            "Epoch 12/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0540 - loss: 4.1881\n",
            "Epoch 13/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0541 - loss: 4.1687\n",
            "Epoch 14/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0618 - loss: 4.1528\n",
            "Epoch 15/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0615 - loss: 4.1435\n",
            "Epoch 16/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0584 - loss: 4.1342\n",
            "Epoch 17/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0601 - loss: 4.1322\n",
            "Epoch 18/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0665 - loss: 4.1147\n",
            "Epoch 19/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0743 - loss: 4.0926\n",
            "Epoch 20/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0715 - loss: 4.0940\n",
            "Epoch 21/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0708 - loss: 4.0807\n",
            "Epoch 22/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0731 - loss: 4.0724\n",
            "Epoch 23/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0729 - loss: 4.0593\n",
            "Epoch 24/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0694 - loss: 4.0712\n",
            "Epoch 25/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0733 - loss: 4.0400\n",
            "Epoch 26/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0782 - loss: 4.0248\n",
            "Epoch 27/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0767 - loss: 4.0188\n",
            "Epoch 28/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0782 - loss: 4.0185\n",
            "Epoch 29/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0756 - loss: 4.0037\n",
            "Epoch 30/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0787 - loss: 4.0005\n",
            "Epoch 31/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0767 - loss: 4.0016\n",
            "Epoch 32/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0820 - loss: 3.9672\n",
            "Epoch 33/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0832 - loss: 3.9610\n",
            "Epoch 34/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0918 - loss: 3.9406\n",
            "Epoch 35/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0878 - loss: 3.9318\n",
            "Epoch 36/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0842 - loss: 3.9465\n",
            "Epoch 37/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0905 - loss: 3.9145\n",
            "Epoch 38/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0918 - loss: 3.9141\n",
            "Epoch 39/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0943 - loss: 3.8761\n",
            "Epoch 40/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0933 - loss: 3.9009\n",
            "Epoch 41/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0978 - loss: 3.8932\n",
            "Epoch 42/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1027 - loss: 3.8606\n",
            "Epoch 43/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1069 - loss: 3.8517\n",
            "Epoch 44/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1066 - loss: 3.8330\n",
            "Epoch 45/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1054 - loss: 3.8484\n",
            "Epoch 46/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1096 - loss: 3.7947\n",
            "Epoch 47/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1096 - loss: 3.8074\n",
            "Epoch 48/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1105 - loss: 3.8125\n",
            "Epoch 49/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1200 - loss: 3.7573\n",
            "Epoch 50/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1173 - loss: 3.7528\n",
            "Epoch 51/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1218 - loss: 3.7375\n",
            "Epoch 52/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1250 - loss: 3.7344\n",
            "Epoch 53/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1211 - loss: 3.7416\n",
            "Epoch 54/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1271 - loss: 3.7234\n",
            "Epoch 55/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1220 - loss: 3.7163\n",
            "Epoch 56/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1259 - loss: 3.7034\n",
            "Epoch 57/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1285 - loss: 3.6938\n",
            "Epoch 58/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1360 - loss: 3.6792\n",
            "Epoch 59/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1372 - loss: 3.6837\n",
            "Epoch 60/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1381 - loss: 3.6496\n",
            "Epoch 61/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1368 - loss: 3.6544\n",
            "Epoch 62/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1399 - loss: 3.6300\n",
            "Epoch 63/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1454 - loss: 3.6289\n",
            "Epoch 64/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1542 - loss: 3.5803\n",
            "Epoch 65/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1498 - loss: 3.6100\n",
            "Epoch 66/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1500 - loss: 3.5914\n",
            "Epoch 67/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1590 - loss: 3.5590\n",
            "Epoch 68/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1606 - loss: 3.5523\n",
            "Epoch 69/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1723 - loss: 3.5275\n",
            "Epoch 70/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1700 - loss: 3.5092\n",
            "Epoch 71/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1618 - loss: 3.5166\n",
            "Epoch 72/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1634 - loss: 3.5288\n",
            "Epoch 73/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1743 - loss: 3.4845\n",
            "Epoch 74/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1728 - loss: 3.4529\n",
            "Epoch 75/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1789 - loss: 3.4600\n",
            "Epoch 76/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1799 - loss: 3.4574\n",
            "Epoch 77/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1802 - loss: 3.4596\n",
            "Epoch 78/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1893 - loss: 3.4275\n",
            "Epoch 79/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1875 - loss: 3.4220\n",
            "Epoch 80/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1878 - loss: 3.4113\n",
            "Epoch 81/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1917 - loss: 3.4043\n",
            "Epoch 82/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1979 - loss: 3.3794\n",
            "Epoch 83/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1984 - loss: 3.3738\n",
            "Epoch 84/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1977 - loss: 3.3608\n",
            "Epoch 85/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2046 - loss: 3.3341\n",
            "Epoch 86/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2041 - loss: 3.3350\n",
            "Epoch 87/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2132 - loss: 3.3134\n",
            "Epoch 88/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2120 - loss: 3.2914\n",
            "Epoch 89/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2145 - loss: 3.2889\n",
            "Epoch 90/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2225 - loss: 3.2752\n",
            "Epoch 91/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2211 - loss: 3.2608\n",
            "Epoch 92/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2199 - loss: 3.2553\n",
            "Epoch 93/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2259 - loss: 3.2390\n",
            "Epoch 94/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2241 - loss: 3.2555\n",
            "Epoch 95/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2239 - loss: 3.2246\n",
            "Epoch 96/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2245 - loss: 3.2362\n",
            "Epoch 97/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2276 - loss: 3.2122\n",
            "Epoch 98/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2397 - loss: 3.2009\n",
            "Epoch 99/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2390 - loss: 3.1889\n",
            "Epoch 100/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2375 - loss: 3.2133\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(<ContrastiveLearning name=contrastive_learning_3, built=False>,\n",
              " <__main__.MiClasificador at 0x7d3cfff69510>)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semisupervised_training(model, classifier, train_data, train_label, unlabelled_data_sin_atipicos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "SIZOUne8935R",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIZOUne8935R",
        "outputId": "b5927e4f-0d69-4e49-91c2-b4e6c33641ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "Test accuracy : 0.04969999939203262\n"
          ]
        }
      ],
      "source": [
        "pred = model.get_encoded_data(x_test)\n",
        "print('Test accuracy :', classifier.score(pred, y_test))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
